
# Information about all exercises in the file 2-approx.do.txt.
# The information can be loaded into a Python list of dicts by
#
# f = open('.2-approx.exerinfo', 'r')
# exer = eval(f.read())
#
[{'answer': '',
  'chapter_exercise': 1,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'linalg1'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:linalg1',
  'no': 1,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [],
             'solution': u'The axioms of a vector space go as follows (see\n"Wikipedia": "https://en.wikipedia.org/wiki/Vector_space", but\nwe use slightly different notation below):\n\n  o The sum of $u$ and $v$, denoted by $u + v$, is in V.\n  o $u + v = v + u$.\n  o $(u + v) + w = u + (v + w)$.\n  o There is a *zero* vector $0$ in V such that $u + 0 = u$.\n  o For each $u$ in V, there is a vector $-u$ in V such that $u + (-u) = 0$.\n  o The scalar multiple of $u$ by $\\gamma$, denoted by $\\gamma u$, is in V.\n  o $\\gamma (u + v) = \\gamma u + \\gamma v$.\n  o $(\\gamma + \\delta)u = \\gamma u + \\delta u$ for scalar $\\gamma$ and $\\delta$.\n  o $\\gamma(\\delta u) = \\gamma\\delta u$.\n  o $1u = u$.\n\nWe must show that each axiom is fulfilled by planar vectors and their\nmathematical rules. Let $u=(a,b)$ and $v=(c,d)$.\n\nAxiom 1:\n\n!bt\n\\[ u+v = (a,b)+(c,d)=(a+c, b+d),\\]\n\n!et\nis a planar vector and therefore in $V$.\n\nAxiom 2:\n\n!bt\n\\[ u+v = (a,b)+(c,d)=(a+c, b+d) = (c+a, d+b) = v + u{\\thinspace .}\\]\n\n!et\n\nAxiom 3:\n\n!bt\n\\[ (u+v) + w = ((a,b) + (c,d)) + (e,f) = (a,b) + ((c,d) + (e,f)) = u + (v+w){\\thinspace .}\\]\n\n!et\n\nAxiom 4: The $(0,0)$ vector is the 0 element,\n\n!bt\n\\[ u + 0 = (a,b) + (0,0) = (a+0, b+0) = (a,b) = u{\\thinspace .}\\]\n\n!et\n\nAxiom 5: Let $-u$ element is $(-a,-b)$, so\n\n!bt\n\\[ u + (-u) = (a,b) + (-a,-b) = (0,0) = 0{\\thinspace .}\\]\n\n!et\n\nAxiom 6:\n\n!bt\n\\[ \\gamma u = \\gamma\\cdot(a,b)= (\\gamma a, \\gamma b),\\]\n\n!et\nis also a planar vector and therefore in $V$.\n\nAxiom 7:\n\n!bt\n\\[ \\gamma (u + v) = \\gamma \\cdot((a,b) + (c,d) = \\gamma (a,b) + \\gamma (c,d){\\thinspace .}\\]\n\n!et\n\nAxiom 8:\n\n!bt\n\\[ (\\gamma + \\delta)u = (\\gamma + \\delta)(a,b) = \\gamma (a,b) + \\delta (a,b) = \\gamma u + \\delta u{\\thinspace .}\\]\n\n!et\n\nAxiom 9:\n\n!bt\n\\[ \\gamma (\\delta u) = \\gamma (\\delta\\cdot (a,b)) = \\gamma (\\delta a, \\delta b) = (\\gamma\\delta a, \\gamma\\delta b) = \\gamma\\delta u{\\thinspace .}\\]\n\n!et\n\nAxiom 10:\n\n!bt\n\\[ 1u = 1(a,b) = (1\\cdot a, 1\\cdot b) = (a,b) = u{\\thinspace .}\\]\n\n!et',
             'text': u'Prove that vectors in the plane spanned by the vector $(a,b)$  form a vector space\nby showing that all the axioms of a vector space are satisfied.'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': u'Let $u=ax+b$ and $v=cx+d$. We verify each axiom.\n\nAxiom 1:\n\n!bt\n\\[ u+v = ax + b + cx + d = (a+c)x + (b + d),\\]\n\n!et\nis also a linear function and therefore in $V$.\n\nAxiom 2:\n\n!bt\n\\[ u+v = ax+b + cx+ d = cx+d + ax+ b = v + u{\\thinspace .}\\]\n\n!et\n\nAxiom 3:\n\n!bt\n\\[ (u+v) + w = (ax+b + cx+ d) + ex + f = ax+b + cx+ d + ex + f\nax+b + (cx+ d + ex + f) = u + (v+w){\\thinspace .}\\]\n\n!et\n\nAxiom 4: The $0x+0=0$ function is the 0 element,\n\n!bt\n\\[ u + 0 = ax + b + 0 = ax + b = u{\\thinspace .}\\]\n\n!et\n\nAxiom 5: Let $-u$ element is $-ax-b$, so\n\n!bt\n\\[ u + (-u) = ax + b + (-ax - b) = 0{\\thinspace .}\\]\n\n!et\n\nAxiom 6:\n\n!bt\n\\[ \\gamma u = \\gamma(ax +b)= \\gamma ax + \\gamma b,\\]\n\n!et\nis also a linear function and therefore in $V$.\n\nAxiom 7:\n\n!bt\n\\[ \\gamma (u + v) = \\gamma (ax+b + cx+ d) = \\gamma ax + \\gamma b + \\gamma cx + \\gamma d = \\gamma(ax + b) + \\gamma(cd + d) = \\gamma u + \\gamma v{\\thinspace .}\\]\n\n!et\n\nAxiom 8:\n\n!bt\n\\[ (\\gamma + \\delta)u = (\\gamma + \\delta)(ax + b) = \\gamma (ax+b) + \\delta (ax+b) = \\gamma u + \\delta u{\\thinspace .}\\]\n\n!et\n\nAxiom 9:\n\n!bt\n\\[ \\gamma (\\delta u) = \\gamma (\\delta(ax+b))) = \\gamma\\delta u{\\thinspace .}\\]\n\n!et\n\nAxiom 10:\n\n!bt\n\\[ 1u = 1(ax+b) = ax+b = u{\\thinspace .}\\]\n\n!et',
             'text': u'Prove that all linear functions of the form $ax+b$ constitute a vector space,\n$a,b\\in\\mathbb{R}$.'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': u'Let $u=ax^2+bx + 1$ and $v=cx^2 + dx + 1$. We try to verify each axiom.\n\nAxiom 1:\n\n!bt\n\\[ u+v = ax^2 + bx + 1 + cx^2 + dx + 1 = (a+c)x^2 + (b+d)x + 2,\\]\n\n!et\nbut this quadratic function is not in $V$ because the constant term is 2\nand not 1. Consequently, quadratic functions of the particular\nform $1 + ax^2 + bx$ do not constitute a vector space.\nThe more general form  $ax^2 + bx +c$ for arbitrary constants $a$, $b$, and\n$c$ makes functions that span a function space.',
             'text': u'Show that all quadratic functions of the form $1 + ax^2 + bx$ *do not*\nconstitute a vector space.'},
            {'aftertext': u'\n',
             'answer': '',
             'file': None,
             'hints': [],
             'solution': u'According to "Wikipedia": "https://en.wikipedia.org/wiki/Inner_product_space",\nan inner product space, with an inner product $(u,v)$, has three axioms\n(we drop the possibility of complex numbers and assume everything is real):\n\n o Symmetry: $(u,v)$ = $(v,u)$\n o Linearity in the first argument: $\\gamma u, v) = \\gamma (u,v)$\n o Positive-definiteness: $(u,u)\\geq 0$ and $(u,u)=0$ implies $u=0$\n\nA possible inner product for linear functions on a domain $\\Omega$ is\n\n!bt\n\\[ (u,v) = \\int_A^B uv{\\, \\mathrm{d}x} = \\int_A^B (ax+b)(cx+d){\\, \\mathrm{d}x}{\\thinspace .}\\]\n\n!et\nSymmetry is obvious since $uv=vu$:\n\n!bt\n\\[ (u,v) = \\int_A^B uv{\\, \\mathrm{d}x} = \\int_A^B vu d = (v,u){\\thinspace .}\\]\n\n!et\nLinearity in the first argument:\n\n!bt\n\\[  (\\gamma u,v) = \\gamma\\int_A^B(\\gamma u)v{\\, \\mathrm{d}x} = \\gamma\\int_A^B uv{\\, \\mathrm{d}x} = \\gamma (u,v){\\thinspace .}\\]\n\n!et\nPositive-definiteness:\n\n!bt\n\\[ (u,u) = \\int_A^B(ax+b)^2{\\, \\mathrm{d}x}\\geq 0,\\]\n\n!et\nsince the integral of a function $f(x)\\geq$ must be greater than or equal to\nzero, and in particular,\n\n!bt\n\\[ (u,u)=0\\quad\\Rightarrow\\quad \\int_A^B(ax+b)^2{\\, \\mathrm{d}x} = 0,\\]\n\n!et\nimplies $ax+b=0$.',
             'text': u'Check out\nthe topic of *inner product spaces*. Suggest a possible inner product\nfor the space of all linear functions of the form $ax+b$, $a,b\\in\\mathbb{R}$,\ndefined on some interval $\\Omega=[A,B]$.\nShow that this particular inner product satisfies the\ngeneral requirements of an inner product in a vector space.'}],
  'text': u'Look up the topic of *vector space* in your favorite linear algebra\nbook or search for the term at Wikipedia.',
  'title': u'Linear algebra refresher',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 2,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'vec111_approx'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:vec:3Dby2D',
  'no': 2,
  'solution': u'We have the vector $\\pmb{f} = (1,1,1)$.\nOur aim is to approximate this with a vector in the vector-space spanned by the unit vectors $\\pmb{\\phi_0}$ and $\\pmb{\\phi_1}$. We seek a solution $u = c_0 \\phi_0 + c_1 \\phi_1$. To do this we use the least-square-method and solve the equation $\\pmb{A c} = \\pmb{b}$. Or written out:\n\n!bt\n\\[\n\\left[\\begin{array}{cc}\nA_{0,0} & A_{0,1} \\\\A_{1,0} & A_{1,1}\n\\end{array}\\right]\n\\left[ \\begin{array}{c} c_0 \\\\ c_1 \\end{array} \\right]\n=\n\\left[ \\begin{array}{c} b_0 \\\\ b_1 \\end{array} \\right]\n\\]\n\n!et\nwhere $A_{i,j} = ( \\pmb{\\phi_i}, \\pmb{\\phi_j} )$ and $b_i = ( \\pmb{\\phi_i}, \\pmb{f} )$.\n\nWe start with $\\pmb{\\phi_0} = (0,1)$, $\\pmb{\\phi_1} = (1,0)$.\nCalculations give\n\n!bt\n\\begin{align*}\nA_{0,0} &= ([1,0],[1,0]) = 1,\\\\\nA_{0,1} &= ([1,0],[0,1]) = 0,\nA_{1,0} &= ([0,1],[1,0]) = 0,\nA_{1,1} &= ([0,1],[0,1]) = 1,\nb_0 &= ([1,0],[1,1,1]) = 1,\nb_0 &= ([0,1],[1,1,1]) = 1.\n\\end{align*}\n\n!et\nThe result becomes $ c_0 = c_1 =1$, and hence\n\n!bt\n\\[ u = 1\\cdot\\pmb{\\phi_0}  + 1\\cdot\\pmb{\\phi_1}.\\]\n\n!et\n\nThen we proceed with\n$\\pmb{\\phi_0} = (2,1)$, $\\pmb{\\phi_1} = (1,2)$.\nCalculations give\n\n!bt\n\\begin{align*}\nA_{0,0} &= ([2,1],[2,1]) = 2\\cdot 2 + 1\\cdot 1 = 5,\nA_{0,1} &= ([2,1],[1,2]) = 2\\cdot 1 + 1\\cdot 2 = 4,\nA_{1,0} &= ([1,2],[2,1]) = 1\\cdot 2 + 2\\cdot 1 = 4,\nA_{1,1} &= ([1,2],[1,2]) = 1\\cdot 1 + 2\\cdot 2 = 5,\nb_0 &= ([2,1],[1,1,1]) = 2\\cdot 1 + 1\\cdot 1 = 3,\nb_0 &= ([1,2],[1,1,1]) = 1\\cdot 1 + 2\\cdot 1 = 3.\n\\end{align*}\n\n!et\nSolving for the $c_i$ values results in $ c_0 = c_1 =\\frac{1}{3}$ and\nhence\n\n!bt\n\\[ u = \\frac{1}{3}\\cdot \\pmb{\\phi_0}  + \\frac{1}{3}\\cdot \\pmb{\\phi_1} .\\]\n\n!et',
  'solution_file': None,
  'subex': [],
  'text': u'Given $\\bm{f} = (1,1,1)$ in $\\mathbb{R}^3$, find the best approximation vector\n$\\bm{u}$ in the plane spanned by the unit vectors $(1,0)$ and $(0,1)$.\nRepeat the calculations using the vectors $(2,1)$ and $(1,2)$.',
  'title': u'Approximate a three-dimensional vector in a plane',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 3,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'parabola_sin'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:parabola_sine',
  'no': 3,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [u'If you make a mesh function `e` of the error\non some mesh with uniformly spaced coordinates in\nthe array `xc`, the integral can be approximated as `np.sqrt(dx*np.sum(e**2))`,\nwhere `dx=xc[0]-xc[1]` is the mesh spacing and `np` is an alias for the\n`numpy` module in Python.'],
             'solution': u"The function ${\\psi}_0=1$ can be used to ``take care of'' of the\nconstant 1 in $f$, while ${\\psi}_1=\\sin(\\pi x)$ can approximate\nthe parabola. The maximum of $f$ is 3/2, so we should use\n$u(x) = 1\\cdot{\\psi}_0 + \\frac{1}{2}{\\psi}_1$.\n\nPlotting and the computation of the $L^2$ error can be done by\n\n!bc pycod\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nxc = np.linspace(0, 1, 101)  # x coordinates for plotting\n\ndef f(x):\n    return 1 + 2*x*(1-x)\n\nimport sympy as sym\nx = sym.symbols('x')\npsi_0 = 1\npsi_1 = sym.sin(sym.pi*x)\n\nhalf = sym.Rational(1,2)\nu = 1*psi_0 + half*psi_1\n\n# How to combine c_0*psi_0 + c_1*psi_1 to match f?\n# Intuitively, c_0=c_1=1...\n# Turn u to function so we can plot and compute with it\nu = sym.lambdify([x], u, modules='numpy')\n\nprint('L2 error of intuitive approximation:', end=' ')\ne = f(xc) - u(xc)\ndx = xc[1] - xc[0]\nprint(np.sqrt(dx*np.sum(e**2)))\n\nplt.plot(xc, f(xc), 'r--')\nplt.plot(xc, u(xc), 'b-')\nplt.legend(['exact', 'intuitive approximation'])\n\n!ec\nThe $L^2$ error becomes $0.0179$.\n\nFIGURE: [fig/parabola_sin_a, width=500 frac=0.7]",
             'text': u'Sketch or plot $f(x)$. Think intuitively how an expansion in terms\nof the basis functions of $V$, ${\\psi}_0(x)=1$, ${\\psi}_1(x)=\\sin(\\pi x)$,\ncan be constructed to yield a best approximation to $f$. Or\nphrased differently, see if you can guess the coefficients $c_0$ and $c_1$\nin the expansion\n\n!bt\n\\[ u(x) = c_0{\\psi}_0 + c_1{\\psi}_1 = c_0 + c_1\\sin (\\pi x){\\thinspace .}\\]\n\n!et\nCompute the $L^2$ error $||f-u||_{L^2}=(\\int_0^1(f-u)^2{\\, \\mathrm{d}x})^{1/2}$.'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': u"The least squares method ends up with a linear system where the\ncoefficient matrix has entries $A_{i,j}=\\int_0^1{\\psi}_i{\\psi}_j{\\, \\mathrm{d}x}$\nand the right-hand side has entries $b_i=\\int_0^1{\\psi}_i{\\, \\mathrm{d}x}$.\nWe can use `sympy` do carry out the integrals:\n\n!bc pycod\n# Do the calculations in the least squares or project method\nA = sym.zeros(2, 2)\nb = sym.zeros(2, 1)\nA[0,0] = sym.integrate(psi_0*psi_0, (x, 0, 1))\nA[0,1] = sym.integrate(psi_0*psi_1, (x, 0, 1))\nA[1,0] = A[0,1]\nA[1,1] = sym.integrate(psi_1*psi_1, (x, 0, 1))\nb[0] = sym.integrate(f(x)*psi_0, (x, 0, 1))\nb[1] = sym.integrate(f(x)*psi_1, (x, 0, 1))\nprint('A:', A)\nprint('b:', b)\nc = A.LUsolve(b)\nc = [sym.simplify(c[i,0]) for i in range(c.shape[0])]\nprint('c:', c, [c_.evalf() for c_ in c])\nu = c[0]*psi_0 + c[1]*psi_1\nprint('u:', u)\n\n!ec\nLooking at the results, we get the linear system\n\n!bt\n\\[\n\\left(\\begin{matrix}1 & \\frac{2}{\\pi}\\\\\\frac{2}{\\pi} & \\frac{1}{2}\\end{matrix}\\right)\n\\left(\\begin{bmatrix}\n\\frac{- 24 \\pi^{2} - 96 + 4 \\pi^{4}}{3 \\pi^{2} \\left(-8 + \\pi^{2}\\right)}\\\\\n\\frac{- 4 \\pi^{2} + 48}{3 \\pi \\left(-8 + \\pi^{2}\\right)}\n\\end{bmatrix}\\right) =\n\\left(\\begin{matrix}\n\\frac{4}{3}\\\\\n\\frac{8}{\\pi^{3}} + \\frac{2}{\\pi}\n\\end{matrix}\\right)\n\\]\n\n!et\nThe resulting best approximation reads\n\n!bt\n\\[ u(x) = \\frac{4 \\left(- \\pi^{2} + 12\\right) \\sin{\\left (\\pi x \\right )}}{3 \\pi \\left(-8 + \\pi^{2}\\right)} + \\frac{- 24 \\pi^{2} - 96 + 4 \\pi^{4}}{3 \\pi^{2} \\left(-8 + \\pi^{2}\\right)}\\approx 1.025 + 0.484\\sin(\\pi x)\\]\n\n!et\nThe $L^2$ error turns out to be $0.00876$.\nTo conclude, the least squares method is slightly better than the intuition\nin this case.\n\nFIGURE: [fig/parabola_sin_b, width=500 frac=0.7]",
             'text': u'Perform the hand calculations for a least squares approximation.'}],
  'text': u'Given the function $f(x)=1 + 2x(1-x)$ on $\\Omega=[0,1]$, we want to\nfind an approximation in the function space\n\n!bt\n\\[ V = \\hbox{span}\\{1, \\sin(\\pi x)\\}{\\thinspace .}\\]\n\n!et',
  'title': u'Approximate a parabola by a sine',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 4,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'exp_powers'],
  'heading': u'=====',
  'hints': [u'Apply the `lest_squares` and\n`comparison_plot` functions in the `approx1D.py` module as these\nmake the exercise easier to solve.'],
  'keywords': None,
  'label': u'fem:approx:exer:exp:powers',
  'no': 4,
  'solution': u"A suitable code is\n\n!bc pycod\nfrom approx1D import least_squares, comparison_plot\nimport matplotlib.pyplot as plt\nimport sympy as sym\nfrom math import factorial\nimport numpy as np\n\nx = sym.Symbol('x')\nf = sym.exp(-x)\n\nOmega = [0, 8]\n\nfor N in 2,4,6:\n    psi = [x**i for i in range(N+1)]\n    u, c = least_squares(f,psi,Omega)\n    print(N, u)\n    comparison_plot(f, u, Omega, filename='tmp_exp_%d' % N,\n                    plot_title='N=%d' % N)\n\n!ec\nFor the case $N=2$ the program prints the following, here edited for clearer\nreading:\n\n!bc\nA:\nMatrix([[8, 32, 512/3], [32, 512/3, 1024], [512/3, 1024, 32768/5]])\nb:\nMatrix([[-exp(-8) + 1], [-9*exp(-8) + 1], [-82*exp(-8) + 2]])\n\nf: exp(-x)\nu: x**2*(-465*exp(-8)/4096 + 105/4096) + x*(-141/512 +\n   405*exp(-8)/512) - 111*exp(-8)/128 + 87/128\n\n!ec \n\nFIGURE: [fig/exp_powers_N2, width=500 frac=0.8]",
  'solution_file': None,
  'subex': [],
  'text': u'Let $V$ be a function space with basis functions $x^i$,\n$i=0,1,\\ldots,N$.  Find the best approximation to $f(x)=\\exp(-x)$ on\n$\\Omega =[0,8]$ among all functions in $V$ for $N=2,4,6$. Illustrate\nthe three approximations in three separate plots.',
  'title': u'Approximate the exponential function by power functions',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 5,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'sin_powers'],
  'heading': u'=====',
  'hints': [u'You can make a loop over $V_1$ and $V_2$, a loop over\n$\\Omega_1$ and $\\Omega_2$, and a loop over $k$. Inside the loops,\ncall the functions `least_squares` and\n`comparison_plot` from the `approx1D` module.\n$N=7$ is a suggested value.'],
  'keywords': None,
  'label': u'fem:approx:exer:sin:powers',
  'no': 5,
  'solution': u"Suitable code is\n\n!bc pycod\nimport sympy as sym\nfrom approx1D import least_squares, comparison_plot\nfrom math import pi\nimport matplotlib.pyplot as plt\n\nx = sym.Symbol('x')\nf = sym.sin(x)\nN = 7\npsi_bases = [[x**i for i in range(1, N+1, 2)],  # V_1\n             [x**i for i in range(0, N+1)]]     # V_2\nsymbolic = False\n\nfor V, psi in enumerate(psi_bases):\n    for domain_no in range(1, 3):\n        for k in range(2, 6):\n            if symbolic:\n                Omega = [0, k*sym.pi] if domain_no == 1 else \\ \n                        [-k*sym.pi/2, k*sym.pi/2]\n            else:\n                # cannot use sym.pi with numerical sympy computing\n                Omega = [0, k*pi] if domain_no == 1 else \\ \n                        [-k*pi/2, k*pi/2]\n\n            u, c = least_squares(f, psi, Omega, symbolic=symbolic)\n\n            comparison_plot(\n                f, u, Omega,\n                ymin=-2, ymax=2,\n                filename='tmp_N%d_V%dOmega%dk%d' %\n                (N, V, k, domain_no),\n                plot_title='sin(x) on [0,%d*pi/2] by %s' %\n                (k, ','.join([str(p) for p in psi])))\n            # Need to kill the plot to proceed!\n        for ext in 'png', 'pdf':\n            cmd = 'doconce combine_images -2 ' + \\ \n                  ' '.join(['tmp_N%d_V%dOmega%dk%d.' %\n                            (N, V, k, domain_no) + ext\n                            for k in range(2, 6)]) + \\ \n                  ' sin_powers_N%d_V%d_Omega%d.' % (N, V, domain_no) + ext\n            print(cmd)\n            os.system(cmd)\n\n# Show the standard Taylor series approximation\nfrom math import factorial, pi\nimport time\nOmega = [0, 12*pi/2.]\nu = 0\nfor k in range(0,N+1):\n    u = u + ((-1)**k*x**(1+2*k))/float(factorial(1+2*k))\n# Shorter: u = sum(((-1)**k*x**(1+2*k))/float(factorial(1+2*k))\n# for k in range(0,10))\ncomparison_plot(f, u, Omega, 'sin_taylor%d' % k,\n                ymin=-1.5, ymax=1.5)\n\n!ec\n\nThe odd powers ($V_1$ space) behave not so good on $\\Omega_{1,k}$,\nbut better on $\\Omega_{2,k}$:\n\nFIGURE: [fig/sin_powers_N7_V1_Omega1, width=800 frac=1] $V_1$ space, $\\Omega_{1,k}$ domain.\n\nFIGURE: [fig/sin_powers_N7_V1_Omega2, width=800 frac=1] $V_1$ space, $\\Omega_{2,k}$ domain.\n\nIncluding also even powers ($V_2$ space) is clearly much better:\n\nFIGURE: [fig/sin_powers_N7_V2_Omega1, width=800 frac=1] $V_2$ space, $\\Omega_{1,k}$ domain.\n\nFIGURE: [fig/sin_powers_N7_V2_Omega2, width=800 frac=1] $V_2$ space, $\\Omega_{2,k}$ domain.\n\nComparison with a standard Taylor series shows that it is very inferior\nas an approximation over the entire domain, but much more accurate\nclose to the origin (as expected, since the Taylor series is constructed\nwith this property, while the least squares method tries to find a good\napproximation over the entire domain).\n\nFIGURE: [fig/sin_taylor7, width=500 frac=0.8]",
  'solution_file': None,
  'subex': [],
  'text': u'In this exercise we want to approximate the sine function by polynomials\nof order $N+1$. Consider two bases:\n\n!bt\n\\begin{align*}\nV_1 &= \\{x, x^3, x^5, \\ldots, x^{N-2}, x^N \\}, \\\\\nV_2 &= \\{1,x,x^2,x^3,\\ldots, x^N\\}{\\thinspace .}\n\\end{align*}\n\n!et\nThe basis $V_1$ is motivated by the fact that the Taylor polynomial\napproximation to the sine function has only odd powers, while $V_2$\nis motivated by the assumption that including the even powers could\nimprove the approximation in a least-squares setting.\n\nCompute the best approximation to $f(x)=\\sin(x)$ among all functions\nin $V_1$ and $V_2$ on two domains of increasing sizes: $\\Omega_{1,k} =\n[0, k\\pi]$, $k=2,3\\ldots,6$ and $\\Omega_{2,k} = [-k\\pi /2, k\\pi/2]$,\n$k=2,3,4,5$.  Make plots for all combinations of $V_1$, $V_2$,\n$\\Omega_1$, $\\Omega_2$, $k=2,3,\\ldots,6$.\n\nAdd a plot of the $N$-th degree Taylor polynomial approximation of\n$\\sin(x)$ around $x=0$.',
  'title': u'Approximate the sine function by power functions',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 6,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': u'Approximation of a discontinuous (or steep) $f(x)$ by sines,\nresults in slow convergence and oscillatory behavior of the\napproximation close to the abrupt changes in $f$.\nThis is known as the "Gibb\'s phenomenon":"http://en.wikipedia.org/wiki/Gibbs_phenomenon".',
  'file': [u'tanh_sines'],
  'heading': u'=====',
  'hints': [u'One may naively call the `least_squares_orth` and `comparison_plot`\nfrom the `approx1D` module in a loop and extend the basis with\none new element in each pass. This approach\nimplies a lot of recomputations.\nA more efficient strategy is to let `least_squares_orth`\ncompute with only one basis function at a time and accumulate\nthe corresponding `u` in the total solution.',
            u'`ffmpeg` or `avconv` may skip frames when plot files are combined to\na movie. Since there are few files and we want to see each of them,\nuse `convert` to make an animated GIF file (`-delay 200` is\nsuitable).'],
  'keywords': None,
  'label': u'fem:approx:exer:tanh:sine1',
  'no': 6,
  'solution': u"The code may read\n\n!bc pycod\nimport sympy as sym\nfrom approx1D import least_squares_orth, comparison_plot\nimport matplotlib.pyplot as plt\n\nx = sym.Symbol('x')\n\n# Naive approach: (not utilizing the fact that i+1 computations can\n# make use of i computations)\ndef naive(f, s, Omega, N=10):\n    psi = []\n    for i in range(N+1):\n        psi.append(sym.sin((2*i+1)*x))\n        u, c = least_squares_orth(f, psi, Omega, symbolic=False)\n        comparison_plot(f, u, Omega, 'tmp_sin%02dx' % i,\n                        legend_loc='upper left', show=True)\n\n# Efficient approach: compute just the matrix diagonal\ndef efficient(f, s, Omega, N=10):\n    u = 0\n    for i in range(N+1):\n        psi = [sym.sin((2*i+1)*x)]\n        next_term, c = least_squares_orth(f, psi, Omega, False)\n        u = u + next_term\n        comparison_plot(f, u, Omega, 'tmp_sin%02dx' % i,\n                        legend_loc='upper left', show=False,\n                        plot_title='s=%g, i=%d' % (s, i))\n\nif __name__ == '__main__':\n    s = 20  # steepness\n    f = sym.tanh(s*(x-sym.pi))\n    from math import pi\n    Omega = [0, 2*pi]  # sym.pi did not work here\n    efficient(f, s, Omega, N=10)\n    # Make movie\n    # avconv/ffmpeg skips frames, use convert instead (few files)\n    cmd = 'convert -delay 200 tmp_sin*.png tanh_sines_approx.gif'\n    os.system(cmd)\n    # Make static plots, 3 figures on 2 lines\n    for ext in 'pdf', 'png':\n        cmd = 'doconce combine_images %s -3 ' % ext\n        cmd += 'tmp_sin00x tmp_sin01x tmp_sin02x tmp_sin04x '\n        cmd += 'tmp_sin07x tmp_sin10x tanh_sines_approx'\n        os.system(cmd)\n    plt.show()\n\n!ec\n\nFIGURE: [fig/tanh_sines, width=800 frac=1]",
  'solution_file': None,
  'subex': [],
  'text': u'Find the best approximation of $f(x) = \\tanh (s(x-\\pi))$ on\n$[0, 2\\pi]$ in the space $V$ with basis\n${\\psi}_i(x) = \\sin((2i+1)x)$, $i\\in{\\mathcal{I}_s} = \\{0,\\ldots,N\\}$.\nMake a movie showing how $u=\\sum_{j\\in{\\mathcal{I}_s}}c_j{\\psi}_j(x)$\napproximates $f(x)$ as $N$ grows. Choose $s$ such that $f$ is\nsteep ($s=20$ is appropriate).',
  'title': u'Approximate a steep function by sines',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 7,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': u'The strange results in b) and c) are due to the choice of\nbasis. In b), ${\\varphi}_i(x)$ is an odd function around\n$x=\\pi/2$ and $x=3\\pi/2$. No combination of basis functions\nis able to approximate the flat regions of $f$.\nAll basis functions in c) are even around $x=\\pi/2$ and $x=3\\pi/2$,\nbut odd at $x=0,\\pi,2\\pi$. With all the sines represented, as in a),\nthe approximation is not constrained with a particular symmetry\nbehavior.',
  'file': [u'tanh_sines_boundary_term'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:tanh:sine3',
  'no': 7,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [],
             'solution': u"With a boundary term $B(x)$ we call `least_squares_orth` with\n`f-B` as right-hand side function, and we must remember to add $B$ to $u$.\n\nWe can extend the code from Exercise ref{fem:approx:exer:tanh:sine1} and\nlet the function `efficient` handle different choices of basis.\nAppropriate code for all three subexercises is\n\n!bc pycod\nimport sympy as sym\nfrom approx1D import least_squares_orth, comparison_plot\nimport matplotlib.pyplot as plt\nx = sym.Symbol('x')\n\ndef efficient(f, B, s, Omega, N=10, basis='a'):\n    u = B\n    for i in range(N+1):\n        if basis == 'a':\n            psi = [sym.sin((i+1)*x)]\n        elif basis == 'b':\n            psi = [sym.sin((2*i+1)*x)]\n        elif basis == 'c':\n            psi = [sym.sin(2*(i+1)*x)]\n        next_term, c = least_squares_orth(f-B, psi, Omega, False)\n        u = u + next_term\n        # Make only plot for i even\n        if i % 2 == 0:\n            comparison_plot(f, u, Omega, 'tmp_sin%02dx' % i,\n                            legend_loc='upper left', show=False,\n                            plot_title='s=%g, i=%d' % (s, i))\n\n\nif __name__ == '__main__':\n    s = 20  # steepness\n    f = sym.tanh(s*(x-sym.pi))\n    from math import pi\n    Omega = [0, 2*pi]  # sym.pi did not work here\n\n    # sin((i+1)*x) basis\n    xL = Omega[0]\n    xR = Omega[1]\n    B = ((xR-x)*f.subs(x, xL) + (x-xL)*f.subs(x, xR))/(xR-xL)\n    for exercise in 'a', 'b', 'c':\n        efficient(f, B, s, Omega, N=16, basis=exercise)\n        # Make movie\n        cmd = 'convert -delay 200 tmp_sin*.png '\n        cmd += 'tanh_sines_boundary_term_%s.gif' % exercise\n        os.system(cmd)\n        # Make static plots, 3 figures on 2 lines\n        for ext in 'pdf', 'png':\n            cmd = 'doconce combine_images %s -3 ' % ext\n            cmd += 'tmp_sin00x tmp_sin02x tmp_sin04x tmp_sin08x '\n            cmd += 'tmp_sin12x tmp_sin16x '\n            cmd += 'tanh_sines_boundary_term_%s' % exercise\n            os.system(cmd)\n\n!ec\n\nFIGURE: [fig/tanh_sines_boundary_term_a, width=800 frac=1]",
             'text': u'Use the basis\n${\\psi}_i(x) = \\sin((i+1)x)$, $i\\in{\\mathcal{I}_s} = \\{0,\\ldots,N\\}$\nand plot $u$ and $f$ for $N=16$. (It suffices to make plots for even $i$.)'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': u'FIGURE: [fig/tanh_sines_boundary_term_b, width=800 frac=1]',
             'text': u'Use the basis from Exercise ref{fem:approx:exer:tanh:sine1},\n${\\psi}_i(x) = \\sin((2i+1)x)$, $i\\in{\\mathcal{I}_s} = \\{0,\\ldots,N\\}$.\n(It suffices to make plots for even $i$.)\nObserve that the approximation converges to a piecewise\nlinear function!'},
            {'aftertext': u'\n\n\n\n\n\n',
             'answer': '',
             'file': None,
             'hints': [],
             'solution': u'FIGURE: [fig/tanh_sines_boundary_term_c, width=800 frac=1]',
             'text': u'Use the basis\n${\\psi}_i(x) = \\sin(2(i+1)x)$, $i\\in{\\mathcal{I}_s} = \\{0,\\ldots,N\\}$,\nand observe that the approximation converges to a piecewise\nconstant function.'}],
  'text': u'We study the same approximation problem as in\nProblem ref{fem:approx:exer:tanh:sine1}. Since ${\\psi}_i(0)={\\psi}_i(2\\pi)=0$\nfor all $i$, $u=0$ at the boundary points $x=0$ and $x=2\\pi$, while\n$f(0)=-1$ and $f(2\\pi)=1$. This discrepancy at the boundary can be\nremoved by adding a boundary function $B(x)$:\n\n!bt\n\\[\nu(x) = B(x) + \\sum_{j\\in{\\mathcal{I}_s}} c_j{\\psi}_j(x),\n\\]\n\n!et\nwhere $B(x)$ has the right boundary values: $B(x_L)=f(x_L)$ and\n$B(x_R)=f(x_R)$, with $x_L=0$ and $x_R=2\\pi$ as the boundary points.\nA linear choice of $B(x)$ is\n\n!bt\n\\[ B(x) = \\frac{(x_R-x)f(x_L) + (x-x_L)f(x_R)}{x_R-x_L}{\\thinspace .}\\]\n\n!et',
  'title': u'Approximate a steep function by sines with boundary adjustment',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 8,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'Fourier_ls'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:Fourier',
  'no': 8,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [],
             'solution': u'From "Wikipedia": "https://en.wikipedia.org/wiki/Fourier_series" we\nhave\n\n!bt\n\\begin{align*}\na_j &= \\frac{2}{L}\\int_0^P f(x)\\cos\\left(j\\frac{2\\pi x}{L}\\right) {\\, \\mathrm{d}x},\\\\\nb_j &= \\frac{2}{L}\\int_0^P f(x)\\sin\\left(j\\frac{2\\pi x}{L}\\right) {\\, \\mathrm{d}x}{\\thinspace .}\n\\end{align*}\n\n!et',
             'text': u'Given a function $f(x)$ on an interval $[0,L]$, look up the formula\nfor the coefficients $a_j$ and $b_j$ in the Fourier series of $f$:\n\n!bt\n\\begin{equation*}\nf(x) = \\frac{1}{2}a_0 +\n\\sum_{j=1}^\\infty a_j\\cos \\left(j\\frac{2\\pi x}{L}\\right)\n+ \\sum_{j=1}^\\infty b_j\\sin \\left(j\\frac{2\\pi x}{L}\\right){\\thinspace .}\n\\end{equation*}\n\n!et'},
            {'answer': '',
             'file': None,
             'hints': [u'You may choose\n\n!bt\n\\begin{equation}\n{\\psi}_{2i} = \\cos\\left( i\\frac{2\\pi}{L}x\\right),\\quad\n{\\psi}_{2i+1} = \\sin\\left( i\\frac{2\\pi}{L}x\\right),\nlabel{fem:approx:exer:Fourier:basis}\n\\end{equation}\n\n!et\nfor $i=0,1,\\ldots,N\\rightarrow\\infty$.'],
             'solution': u'The entries in the linear system arising from the least squares method\nare $A_{i,j}=\\int_0^L{\\psi}_i{\\psi}_j{\\, \\mathrm{d}x}$ and $b_i=\\int_0^L\nf(x){\\psi}_i {\\, \\mathrm{d}x}$. To avoid name clash between the right-hand side\ncomponents of the linear system and the $b_i$ coefficients in the\nFourier series, we use the symbol $q_i$ for the former.\nWith the basis functions in\n(ref{fem:approx:exer:Fourier:basis}) we get four different types\nof integrals:\n\n!bt\n\\begin{align*}\nA_{2i,2j} &= \\int_0^L \\cos\\left( i\\frac{2\\pi}{L}x\\right)\n\\cos\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x} = A_{2j,2i},\\\\\nA_{2i, 2j+1} &= \\int_0^L \\cos\\left( i\\frac{2\\pi}{L}x\\right)\n\\sin\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\\\\nA_{2i+1,2j} &= \\int_0^L \\sin\\left( i\\frac{2\\pi}{L}x\\right)\n\\cos\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\\\\nA_{2i+1, 2j+1} &= \\int_0^L \\sin\\left( i\\frac{2\\pi}{L}x\\right)\n\\sin\\left( j\\frac{2\\pi}{L}x\\right)dx,\\\\\nq_{2i} &= \\int_0^L f(x)\\cos\\left( i\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\\\\nq_{2i+1} &= \\int_0^L f(x)\\sin\\left( i\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}{\\thinspace .}\n\\end{align*}\n\n!et\nNow, the sine and cosine basis functions are orthogonal on $[0,L]$.\nWe have in general\n\n!bt\n\\begin{align*}\n\\int_0^L\n\\cos\\left( i\\frac{2\\pi}{L}x\\right) \\cos\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}\n&=0,\\quad i\\neq j,\\\\\n\\int_0^L\n\\cos\\left( i\\frac{2\\pi}{L}x\\right) \\cos\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}\n&=\\frac{L}{2},\\quad i= j\\neq 0,\\\\\n\\int_0^L\n\\cos\\left( i\\frac{2\\pi}{L}x\\right) \\cos\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}\n&=L,\\quad i= j= 0,\\\\\n\\int_0^L\n\\sin\\left( i\\frac{2\\pi}{L}x\\right) \\sin\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}\n&=0,\\quad i\\neq j,\\\\\n\\int_0^L\n\\sin\\left( i\\frac{2\\pi}{L}x\\right) \\sin\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}\n&=\\frac{L}{2},\\quad i= j,\\\\\n\\int_0^L\n\\cos\\left( i\\frac{2\\pi}{L}x\\right) \\sin\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}\n&=0{\\thinspace .}\n\\end{align*}\n\n!et\nThese results imply that only diagonal terms in the coefficient matrix\nare different from zero. We have\n\n!bt\n\\begin{align*}\nA_{0,0} &= L,\\\\\nA_{2i,2i} &= \\frac{L}{2},\\quad i>0,\\\\\nA_{2i+1,2i+1} &= \\frac{L}{2}{\\thinspace .}\n\\end{align*}\n\n!et\nThe unknown vector with components $c_i$ must be arranged as\n\n!bt\n\\[ (a_0, b_1, a_1, b_2, a_2, b_3, \\ldots){\\thinspace .} \\]\n\n!et\nWe then get\n\n!bt\n\\[ A_{0,0}a_0=q_0,\\quad A_{1,1}b_1=q_1,\\quad A_{2,2}a_1=q_2,\\quad A_{3,3}b_2=q_3,\\ldots\\]\n\n!et\nThese equations lead to the formulas\n\n!bt\n\\begin{align*}\na_0 &= \\frac{1}{L}\\int_0^P f(x){\\, \\mathrm{d}x},\\\\\nb_1 &= \\frac{2}{L}\\int_0^P f(x)\\sin\\left( \\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\\\\na_1 &= \\frac{2}{L}\\int_0^P f(x)\\cos\\left( \\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\\\\nb_2 &= \\frac{2}{L}\\int_0^P f(x)\\sin\\left( 2\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\\\\na_2 &= \\frac{2}{L}\\int_0^P f(x)\\cos\\left( 2\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x}{\\thinspace .}\n\\end{align*}\n\n!et\nwhich can be generalized to\n\n!bt\n\\begin{align*}\na_0 &= \\frac{1}{L}\\int_0^P f(x){\\, \\mathrm{d}x},\\\\\na_j &= \\frac{2}{L}\\int_0^P f(x)\\cos\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\ j>0,\\\\\nb_j &= \\frac{2}{L}\\int_0^P f(x)\\sin\\left( j\\frac{2\\pi}{L}x\\right){\\, \\mathrm{d}x},\\ j>0,\n\\end{align*}\n\n!et\nand these are the standard formulas for the Fourier coefficients in a)\nif we recognize that the $a_0$ above is twice the $a_0$ in the\nexpressions in a).',
             'text': u'Let an infinite-dimensional vector space $V$ have the basis functions\n$\\cos j\\frac{2\\pi x}{L}$ for $j=0,1,\\dots,\\infty$ and\n$\\sin j\\frac{2\\pi x}{L}$ for $j=1,\\dots,\\infty$.  Show that the least squares\napproximation method from Section ref{fem:approx:global} leads to a\nlinear system whose solution coincides with the standard formulas for\nthe coefficients in a Fourier series of $f(x)$ (see also\nSection ref{fem:approx:global:Fourier}).'},
            {'aftertext': u'\n',
             'answer': '',
             'file': None,
             'hints': [],
             'solution': u"The formulas give\n\n!bt\n\\begin{align*}\na_0 &= 2\\int_0^1 f(x){\\, \\mathrm{d}x} = 2\\int_{\\frac{1}{2}}^1 {\\, \\mathrm{d}x},\\\\\na_j &= 2\\int_0^1 f(x)\\cos\\left( 2j\\pi x\\right){\\, \\mathrm{d}x}\n= 2\\int_{\\frac{1}{2}}^1 \\cos\\left( 2j\\pi x\\right){\\, \\mathrm{d}x},\\\\\nb_j &= 2\\int_{\\frac{1}{2}}^1 \\sin\\left( 2j\\pi x\\right){\\, \\mathrm{d}x}{\\thinspace .}\n\\end{align*}\n\n!et\nThe integrals are readily computed by `sympy`:\n\n!bc pyshell\n>>> import sympy as sym\n>>> j = sym.symbols('k', integer=True)\n>>> x = sym.symbols('x', real=True)\n>>> I = integrate(cos(2*j*pi*x), (x,Rational(1,2),1))\n>>> I\n0\n>>> I = integrate(cos(2*0*pi*x), (x,Rational(1,2),1))\n>>> I\n1/2\n>>> I = integrate(sin(2*j*pi*x), (x,Rational(1,2),1))\n>>> I\n(-1)**j/(2*pi*j) - 1/(2*pi*j)\n\n!ec\nThis means that we have the series\n\n!bt\n\\[ u(x) = \\frac{1}{2} + 2\\sum_{j=1}^\\infty \\frac{(-1)^j - 1}{2\\pi j}\n\\sin\\left( 2j\\pi x\\right){\\thinspace .}\\]\n\n!et\nWe only get a nonzero coefficient for $j$ odd:\n\n!bt\n\\[ u(x) = \\frac{1}{2} -2\\sum_{k=1}^\\infty \\frac{1}{(2k+1)\\pi}\n\\sin\\left( 2(2k+1)\\pi x\\right){\\thinspace .}\\]\n\n!et\n\nAppropriate computer code for visualizing the series goes like\n\n!bc pypro\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom math import pi\nfrom numpy import sin\n\ndef Heaviside_series(x, N):\n    s = 0.5\n    for k in range(N):\n        s += -2.0/((2*k+1)*pi)*sin(2*(2*k+1)*pi*x)\n    return s\n\nx = np.linspace(0, 1, 1001)\nfor N in 5, 100:\n    H = Heaviside_series(x, N)\n    plt.figure()\n    plt.plot(x, H)\n    plt.legend(['$N=%d$' % N], loc='upper left')\n    plt.savefig('tmp_%d.png' % N)\n    plt.savefig('tmp_%d.pdf' % N)\nplt.show()\n\n!ec\n\nFIGURE: [fig/Fourier_Heaviside, width=800 frac=1]\n\nWe clearly see the Gibbs' phenomenon: oscillations and overshoot around\nthe point of discontinuity in the function we try to approximate.",
             'text': u'Choose $f(x) = H(x-\\frac{1}{2})$ on $\\Omega=[0,1]$, where $H$ is the\nHeaviside function: $H(x)=0$ for $x<0$, $H(x)=1$ for $x>0$ and\n$H(0)=\\frac{1}{2}$. Find the coefficients $a_j$ and $b_j$ in the\nFourier series for $f(x)$. Plot the sum for $j=2N+1$, where $N=5$ and\n$N=100$.'}],
  'text': u'',
  'title': u'Fourier series as a least squares approximation',
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 9,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'tanh_Lagrange'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:tanh:Lagrange',
  'no': 9,
  'solution': u"The following code does the work (symbolically):\n\n!bc pypro\nimport sys, os\nsys.path.insert(0, os.path.join(os.pardir, 'src'))\nfrom approx1D import interpolation, comparison_plot\nfrom Lagrange import Lagrange_polynomials\nimport sympy as sym\n\nx = sym.Symbol('x')\nOmega = [0,1]\nN_values = 3, 7, 11, 15\n\nfor s in 5, 20:\n    f = -sym.tanh(s*(x-0.5))  # sympy expression\n    for distribution in 'uniform', 'Chebyshev':\n        for N in N_values:\n            phi, points = Lagrange_polynomials(\n                x, N, Omega,\n                point_distribution=distribution)\n\n            u, c = interpolation(f, phi, points)\n            filename = 'tmp_tanh_%d_%d_%s' % (N, s, distribution)\n            comparison_plot(f, u, Omega, filename,\n                            plot_title='s=%g, N=%d, %s points' %\n                            (s, N, distribution))\n        # Combine plot files (2x2)\n        for ext in 'png', 'pdf':\n            cmd = 'doconce combine_images ' + ext + ' '\n            cmd += ' '.join([\n                'tmp_tanh_%d_%d_%s' % (N, s, distribution)\n                for N in N_values])\n            cmd += ' tanh_Lagrange_%s_s%s' % (distribution, s)\n            os.system(cmd)\n\n!ec\n\nFor a smooth function ($s=5$), the difference between uniform points and\nChebyshev nodes is not substantial:\n\nFIGURE: [fig/tanh_Lagrange_uniform_s5, width=800 frac=1]\n\nFIGURE: [fig/tanh_Lagrange_Chebyshev_s5, width=800 frac=1]\n\nHowever, for a steep function ($s=20$) the overshoot and oscillations\nassociated with uniform points must be considered unacceptable for\nlarger $N$ values:\n\nFIGURE: [fig/tanh_Lagrange_uniform_s20, width=800 frac=1]\n\nSwitching to Chebyshev points does give a great improvement, but\nwe still have oscillatory approximations:\n\nFIGURE: [fig/tanh_Lagrange_Chebyshev_s20, width=800 frac=1]",
  'solution_file': None,
  'subex': [],
  'text': u'Use interpolation with uniformly distributed\npoints and Chebychev nodes to approximate\n\n!bt\n\\begin{equation*} f(x) = -\\tanh(s(x-\\frac{1}{2})),\\quad x\\in [0,1],\\end{equation*}\n\n!et\nby Lagrange polynomials for $s=5$ and $s=20$, and $N=3,7,11,15$.\nCombine $2\\times 2$ plots of the approximation for the four\n$N$ values, and create such figures for the four combinations of\n$s$ values and point types.',
  'title': u'Approximate a steep function by Lagrange polynomials',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 10,
  'chapter_no': 1,
  'chapter_title': u'Function approximation by global functions',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'tanh_Lagrange_regression'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:tanh:Lagrange:regression',
  'no': 10,
  'solution': u"We start out with the program from\nProblem ref{fem:approx:exer:tanh:Lagrange}. This time we need\nto call `Lagrange_polynomails` twice: first to compute the ${\\psi}(x)$\nfunctions (of degree $N$) and then to compute the data points corresponding\nto a uniform or Chebyshev distribution of $2N+1$ nodes.\n\n!bc pypro\nimport sys, os\nsys.path.insert(0, os.path.join(os.pardir, 'src'))\nfrom approx1D import regression, comparison_plot\nfrom Lagrange import Lagrange_polynomials\nimport sympy as sym\nimport numpy as np\n\nx = sym.Symbol('x')\nOmega = [0,1]\nN_values = 3, 7, 11, 15\n\nfor s in 5, 20:\n    f = -sym.tanh(s*(x-0.5))  # sympy expression\n    for distribution in 'uniform', 'Chebyshev':\n        for N in N_values:\n            # Compute the points from a 2*N Lagrange polynomial\n            dummy, points = Lagrange_polynomials(\n                x, 2*N, Omega,\n                point_distribution=distribution)\n            # Compute phi from N points Lagrange polynomial\n            phi, dummy = Lagrange_polynomials(\n                x, N, Omega,\n                point_distribution=distribution)\n            points = np.array(points, dtype=float)\n            point_values = -np.tanh(s*(points-0.5))\n\n            u, c = regression(f, phi, points)\n            filename = 'tmp_tanh_%d_%d_%s' % (N, s, distribution)\n            comparison_plot(f, u, Omega, filename,\n                            plot_title='s=%g, N=%d, %s points' %\n                            (s, N, distribution),\n                            points=points, point_values=point_values,\n                            points_legend='%s points' % (2*N))\n        # Combine plot files (2x2)\n        for ext in 'png', 'pdf':\n            cmd = 'doconce combine_images ' + ext + ' '\n            cmd += ' '.join([\n                'tmp_tanh_%d_%d_%s' % (N, s, distribution)\n                for N in N_values])\n            cmd += ' tanh_Lagrange_regr_%s_s%s' % (distribution, s)\n            os.system(cmd)\n\n!ec\nAn important point is to convert `points` to a `numpy` array using\n`dtype=float`. Leaving out this second argument makes an array\nof objects of symbolic expressions, and we cannot apply `tanh` to it.\n\nThe oscillatory behavior is much reduced using more points and a\nregression method, and the difference between uniform and Chebyshev\npoints is minor, even in the steep case $s=20$:\n\nFIGURE: [fig/tanh_Lagrange_regr_uniform_s20, width=800 frac=1]\n\nFIGURE: [fig/tanh_Lagrange_regr_Chebyshev_s20, width=800 frac=1]",
  'solution_file': None,
  'subex': [],
  'text': u'Redo Problem ref{fem:approx:exer:tanh:Lagrange}, but apply a regression\nmethod with $N$-degree Lagrange polynomials and $2N+1$\ndata points. Recall that\nProblem ref{fem:approx:exer:tanh:Lagrange} applies $N+1$ points and\nthe resulting approximation interpolates $f$ at these points, while\na regression method with more points does not interpolate $f$ at the\ndata points.\nDo more points and a regression method help reduce\nthe oscillatory behavior of Lagrange polynomial approximations?',
  'title': u'Approximate a steep function by Lagrange polynomials and regression',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 1,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_numberings1'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:mesh1',
  'no': 11,
  'solution': u'We can write up figure sketches and the data structure in code:\n\n!bc pypro\n# P1 elements\n# Left to right numbering\n"""\nelements: |--0--|--1--|--2--|\nnodes:    0     1     2     3\n"""\n\nnodes    = [0, 1, 1.2, 2]\nelements = [[0,1], [1,2], [2,3]]\n\n# Right to left numbering\n"""\nelements: |--2--|--1--|--0--|\nnodes:    3     2     1     0\n"""\n\nnodes    = [2, 1.2, 1, 0]\nelements = [[1,0], [2,1], [3,2]]\n\n\n# P2 elements\n\n# Left to right numbering\n"""\nelements: |--0--|--1--|--2--|\nnodes:    0  1  2  3  4  5  6\n"""\n\nnodes = [0, 0.5, 1, 1.1, 1.6, 2]\nelements = [[0,1,2], [2,3,4], [4,5,6]]\n\n# Right to left numbering\n"""\nelements: |--2--|--1--|--0--|\nnodes:    6  5  4  3  2  1  0\n"""\n\nnodes = [2, 1.6, 1.2, 1.1, 1, 0.5, 0]\nelements = [[2,1,0], [4,3,2], [6,5,4]]\n\n!ec',
  'solution_file': None,
  'subex': [],
  'text': u'Consider a domain $\\Omega =[0,2]$ divided into the three elements\n$[0,1]$, $[1,1.2]$, and $[1.2,2]$.\n\nFor P1 and P2 elements, set up the list of coordinates and nodes\n(`nodes`) and the numbers of the nodes that belong to each element\n(`elements`) in two cases: 1) nodes and elements numbered from left to\nright, and 2) nodes and elements numbered from right to left.',
  'title': u'Define nodes and elements',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 2,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_numberings2'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:mesh2',
  'no': 12,
  'solution': u'Written in Python, the solution becomes\n\n!bc pypro\n# P1 elements\n# Left to right numbering\n"""\nelements: |--0--|--1--|--2--|\nvertices: 0     1     2     3\ndofs:     0     1     2     3\n"""\n# elements:   0   1   2\n# vertices: 0   1   2   3\n\nvertices = [0, 1, 1.2, 2]\ncells    = [[0,1], [1,2], [2,3]]\ndof_map  = [[0,1], [1,2], [2,3]]\n\n# Right to left numbering\n"""\nelements: |--2--|--1--|--0--|\nvertices: 3     2     1     0\ndofs:     3     2     1     0\n"""\n\nvertices = [2, 1.2, 1, 0]\ncells    = [[1,0], [2,1], [3,2]]\ndof_map  = [[1,0], [2,1], [3,2]]\n\n\n# P2 elements\n\n# Left to right numbering\n# elements:   0   1   2\n"""\nelements: |--0--|--1--|--2--|\nvertices: 0     1     2     3\ndofs:     0  1  2  3  4  5  6\n"""\n\nvertices = [0, 1, 1.2, 2]\ncells    = [[0,1], [1,2], [2,3]]\ndof_map  = [[0,1,2], [2,3,4], [4,5,6]]\n\n# Right to left numbering\n# elements:   2   1   0\n"""\nelements: |--2--|--1--|--0--|\nvertices: 3     2     1     0\ndofs:     6  5  4  3  2  1  0\n"""\n\nvertices = [2, 1.2, 1, 0]\ncells    = [[1,0], [2,1], [3,2]]\ndof_map  = [[2,1,0], [4,3,2], [6,5,4]]\n\n!ec',
  'solution_file': None,
  'subex': [],
  'text': u'Repeat Problem ref{fem:approx:fe:exer:mesh1}, but define the\ndata structures `vertices`, `cells`, and `dof_map` instead of\n`nodes` and `elements`.',
  'title': u'Define vertices, cells, and dof maps',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 3,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_sparsity_pattern'],
  'heading': u'=====',
  'hints': [u'A matrix entry $(i,j)$ is nonzero if $i$ and $j$ are nodes in the\nsame element.'],
  'keywords': None,
  'label': u'fem:approx:fe:exer:defmesh:sparsity',
  'no': 13,
  'solution': u"If we create an empty matrix, we can run through all elements and\nthen over all local node pairs and mark that the corresponding\nentry $(i,j)$ in the global matrix is a nonzero entry.\nThe `elements` data structure is sufficient. Below is a program\nthat fills matrix entries with an `X` and prints the matrix sparsity\npattern.\n\n!bc pypro\n\ndef sparsity_pattern(elements, N_n):\n    import numpy as np\n    matrix = np.zeros((N_n, N_n), dtype=str)\n    matrix[:,:] = '0'\n    for e in elements:\n        for i in e:\n            for j in e:\n                matrix[i,j] = 'X'\n    matrix = matrix.tolist()\n    matrix = '\\n'.join([' '.join([matrix[i][j]\n                                  for j in range(len(matrix[i]))])\n                        for i in range(len(matrix))])\n    return matrix\n\n\nprint('\\nP1 elements, left-to-right numbering')\nN_n = 4\nelements = [[0,1], [1,2], [2,3]]\nprint(sparsity_pattern(elements, N_n))\n\nprint('\\nP1 elements, right-to-left numbering')\nelements = [[1,0], [2,1], [3,2]]\nprint(sparsity_pattern(elements, N_n))\n\nprint('\\nP2 elements, left-to-right numbering')\nN_n = 7\nelements = [[0,1,2], [2,3,4], [4,5,6]]\nprint(sparsity_pattern(elements, N_n))\n\nprint('\\nP1 elements, right-to-left numbering')\nelements = [[2,1,0], [4,3,2], [6,5,4]]\nprint(sparsity_pattern(elements, N_n))\n\n!ec\nThe output becomes\n\n!bc\nP1 elements, left-to-right numbering\nX X 0 0\nX X X 0\n0 X X X\n0 0 X X\n\nP1 elements, right-to-left numbering\nX X 0 0\nX X X 0\n0 X X X\n0 0 X X\n\nP2 elements, left-to-right numbering\nX X X 0 0 0 0\nX X X 0 0 0 0\nX X X X X 0 0\n0 0 X X X 0 0\n0 0 X X X X X\n0 0 0 0 X X X\n0 0 0 0 X X X\n\nP1 elements, right-to-left numbering\nX X X 0 0 0 0\nX X X 0 0 0 0\nX X X X X 0 0\n0 0 X X X 0 0\n0 0 X X X X X\n0 0 0 0 X X X\n0 0 0 0 X X X\n\n!ec",
  'solution_file': None,
  'subex': [],
  'text': u'Problem ref{fem:approx:fe:exer:mesh1} describes a element mesh\nwith a total of five elements, but with two different element and\nnode orderings. For each of the two orderings,\nmake a $5\\times 5$ matrix and fill in the entries that will be nonzero.',
  'title': u'Construct matrix sparsity patterns',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 4,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_sin_P1'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:Asinwt:symbolic',
  'no': 14,
  'solution': u"Here are suitable `sympy` commands:\n\n!bc pypro\nimport sympy as sym\n# Mesh: |--------|-------|\n#       0      pi/2      pi\n#\n# Basis functions:\n#\n#   phi_0   phi_1   phi_2\n#     \\      /\\      /\n#      \\    /  \\    /\n#       \\  /    \\  /\n#        \\/      \\/\n#     |-------|-------|\n#     0      pi/2     pi\n\nx = sym.Symbol('x')\nA = sym.zeros(3,3)\nf = sym.sin\n\nphi_0 = 1 - (2*x)/sym.pi\nphi_1l = 2*x/sym.pi          # left part of phi_1\nphi_1r = 2 - (2*x)/sym.pi    # right part of phi_1\nphi_2 = x/(sym.pi/2) - 1\nnode_0 = 0\nnode_1 = sym.pi/2\nnode_2 = sym.pi\n\n# Diagonal terms\nA[0,0] = sym.integrate(phi_0**2,  (x, node_0, node_1))\nA[1,1] = sym.integrate(phi_1l**2, (x, node_0, node_1)) + \\\n         sym.integrate(phi_1r**2, (x, node_1, node_2))\nA[2,2] = sym.integrate(phi_2**2,  (x, node_1, node_2))\n\n# Off-diagonal terms\nA[0,1] = sym.integrate(phi_0*phi_1l, (x, node_0, node_1))\nA[1,0] = A[0,1]\n\nA[1,2] = sym.integrate(phi_1r*phi_2, (x, node_1, node_2))\nA[2,1] = A[1,2]\n\nprint('A:\\n', A)  # Can compare with general matrix, h=pi/2\n\nb = sym.zeros(3,1)\n\nb[0] = sym.integrate(phi_0*f(x),  (x, node_0, node_1))\nb[1] = sym.integrate(phi_1l*f(x), (x, node_0, node_1)) + \\\n       sym.integrate(phi_1r*f(x), (x, node_1, node_2))\nb[2] = sym.integrate(phi_2*f(x),  (x, node_1, node_2))\n\nprint('b:\\n', b)\n\nc = A.LUsolve(b)\nprint('c:\\n', c)\n\nfor i in range(len(c)):\n    print('c[%d]=%g' % (i, c[i].evalf()))\nprint('u(pi/2)=%g' % c[1])\n\n# For reports\nprint(sym.latex(A))\nprint(sym.latex(b))\nprint(sym.latex(c))\n\n!ec\nRunning the program, we get the matrix system\n\n!bt\n\\[\n\\left[\\begin{matrix}\\frac{\\pi}{6} & \\frac{\\pi}{12} & 0\\\\\\frac{\\pi}{12} & \\frac{\\pi}{3} & \\frac{\\pi}{12}\\\\0 & \\frac{\\pi}{12} & \\frac{\\pi}{6}\\end{matrix}\\right]\n\\left[\\begin{matrix}\\frac{1}{\\pi} \\left(- \\frac{24}{\\pi} + 8\\right)\\\\\\frac{-28 + \\frac{168}{\\pi}}{7 \\pi}\\\\\\frac{1}{\\pi} \\left(- \\frac{24}{\\pi} + 8\\right)\\end{matrix}\\right]\n=\n\\left[\\begin{matrix}- \\frac{2}{\\pi} + 1\\\\\\frac{4}{\\pi}\\\\- \\frac{2}{\\pi} + 1\\end{matrix}\\right]\n\\]\n\n!et\nThe solution at the midpoint is $1.15847$, i.e., 16% error.",
  'solution_file': None,
  'subex': [],
  'text': u'Perform symbolic calculations to find formulas for the coefficient\nmatrix and right-hand side when approximating $f(x) = \\sin (x)$ on\n$\\Omega=[0, \\pi]$ by two P1 elements of size $\\pi/2$.  Solve the\nsystem and compare $u(\\pi/2)$ with the exact value 1.',
  'title': u'Perform symbolic finite element computations',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 5,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_tanh_P1P2'],
  'heading': u'=====',
  'hints': [u'You can automate the computations by calling the `approximate` method\nin the `fe_approx1D_numint` module.'],
  'keywords': None,
  'label': u'fem:approx:exer:tanh:P1P2',
  'no': 15,
  'solution': u"The set of calls to `approximate` becomes\n\n!bc pycod\nfrom fe_approx1D_numint import approximate\nfrom sympy import tanh, Symbol\nx = Symbol('x')\n\nsteepness = 20\narg = steepness*(x-0.5)\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre2',\n            d=1, N_e=4, filename='fe_p1_tanh_4e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre2',\n            d=1, N_e=8, filename='fe_p1_tanh_8e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre2',\n            d=1, N_e=16, filename='fe_p1_tanh_16e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre3',\n            d=2, N_e=2, filename='fe_p2_tanh_2e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre3',\n            d=2, N_e=4, filename='fe_p2_tanh_4e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre3',\n            d=2, N_e=8, filename='fe_p2_tanh_8e')\n\n!ec\n\nFIGURE: [fig/fe_p1_tanh, width=800 frac=1]\n\nFIGURE: [fig/fe_p2_tanh, width=800 frac=1]",
  'solution_file': None,
  'subex': [],
  'text': u'Given\n\n!bt\n\\begin{equation*} f(x) = \\tanh(s(x-\\frac{1}{2}))\\end{equation*}\n\n!et\nuse the Galerkin or least squares method with finite elements to find\nan approximate function $u(x)$. Choose $s=20$ and try\n$N_e=4,8,16$ P1 elements and\n$N_e=2,4,8$ P2 elements.\nIntegrate $f{\\varphi}_i$ numerically.',
  'title': u'Approximate a steep function by P1 and P2 elements',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 6,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_tanh_P3P4'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:exer:tanh:P3P4',
  'no': 16,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [],
             'solution': u"We can easily adopt the code from Exercise ref{fem:approx:exer:tanh:P1P2}:\n\n!bc pycod\nfrom fe_approx1D_numint import approximate, u_glob\nfrom sympy import tanh, Symbol, lambdify\nx = Symbol('x')\n\nsteepness = 20\narg = steepness*(x-0.5)\n\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre4',\n            d=3, N_e=1, filename='fe_p3_tanh_1e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre4',\n            d=3, N_e=2, filename='fe_p3_tanh_2e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre4',\n            d=3, N_e=4, filename='fe_p3_tanh_4e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre5',\n            d=4, N_e=1, filename='fe_p4_tanh_1e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre5',\n            d=4, N_e=2, filename='fe_p4_tanh_2e')\napproximate(tanh(arg), symbolic=False, numint='GaussLegendre5',\n            d=4, N_e=4, filename='fe_p4_tanh_4e')\n\n!ec\n\nFIGURE: [fig/fe_p3_tanh, width=800 frac=1]\n\nFIGURE: [fig/fe_p4_tanh, width=800 frac=1]",
             'text': u'Solve Problem ref{fem:approx:exer:tanh:P1P2} using $N_e=1,2,4$ P3 and P4\nelements.'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': u"The coefficients arising from the interpolation method are trivial to compute\nsince $c_i=f(x_i)$, where $x_i$ are the global nodes. The function\n`u_glob` in the `fe_approx1D_numint` module can be used to compute\nappropriate arrays for plotting the resulting finite element function.\nWe create plots where the finite element approximation is shown along\nwith $f(x)$ and the interpolation points.\nSince `u_glob` requires the `vertices`, `cells`, and `dof_map` data\nstructures, we must compute these for the values of number of\nelements ($N_e$) and the polynomial degree ($d$).\n\n!bc pycod\n# Interpolation method\nimport numpy as np\nimport matplotlib.pyplot as plt\nf = lambdify([x], tanh(arg), modules='numpy')\n\n# Compute exact f on a fine mesh\nx_fine = np.linspace(0, 1, 101)\nf_fine = f(x_fine)\n\nfor d in 3, 4:\n    for N_e in 1, 2, 4:\n        h = 1.0/N_e  # element length\n        vertices = [i*h for i in range(N_e+1)]\n        cells = [[e, e+1] for e in range(N_e)]\n        dof_map = [[d*e + i for i in range(d+1)] for e in range(N_e)]\n        N_n = d*N_e + 1  # Number of nodes\n        x_nodes = np.linspace(0, 1, N_n)  # Node coordinates\n        U = f(x_nodes)  # Interpolation method samples node values\n        x, u, _ = u_glob(U, vertices, cells, dof_map,\n                         resolution_per_element=51)\n        plt.figure()\n        plt.plot(x, u, '-', x_fine, f_fine, '--',\n                 x_nodes, U, 'bo')\n        plt.legend(['%d P%d elements' % (N_e, d),\n                    'exact', 'interpolation points'],\n                   loc='upper left')\n        plt.savefig('tmp_%d_P%d.pdf' % (N_e, d))\n        plt.savefig('tmp_%d_P%d.png' % (N_e, d))\nplt.show()\n\n!ec\n\nFIGURE: [fig/tanh_fe_interpol_P3, width=800 frac=1]\n\nFIGURE: [fig/tanh_fe_interpol_P4, width=800 frac=1]",
             'text': u'How will an interpolation method work in\nthis case with the same number of nodes?'}],
  'text': u'',
  'title': u'Approximate a steep function by P3 and P4 elements',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 7,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'Pd_approx_error'],
  'heading': u'=====',
  'hints': [u'Run a series of experiments: $(h_i,E_i)$, $i=0,\\ldots,m$, where $E_i$\nis the $L^2$ norm of the error corresponding to element length $h_i$.\nAssume an error model $E=Ch^r$ and compute $r$ from two successive\nexperiments:\n\n286 <<<!!MATH_BLOCK\nHopefully, the sequence $r_0,\\ldots,r_{m-1}$ converges to the true\n$r$, and $r_{m-1}$ can be taken as an approximation to $r$.\nRun such experiments for different $d$ for the different $f(x)$ functions.',
            u'The `approximate` function in `fe_approx1D_numint.py` is handy for\ncalculating the numerical solution. This function returns the\nfinite element solution as the coefficients $\\left\\{ {c}_i \\right\\}_{i\\in{\\mathcal{I}_s}}$.\nTo compute $u$, use `u_glob` from the same module.\nUse the Trapezoidal rule to integrate the $L^2$ error:\n\n95 <<<!!CODE_BLOCK  pycod\nThe reason for this Trapezoidal integration is\nthat `u_glob` returns coordinates `xc` and corresponding `u` values\nwhere some of the coordinates (the cell vertices) coincides, because\nthe solution is computed in one element at a time, using all local\nnodes. Also note that there are many coordinates in $xc$ per cell\nsuch that we can accurately compute the error inside each cell.'],
  'keywords': None,
  'label': u'fem:approx:fe:exer:Asinwt:interpol:error',
  'no': 17,
  'solution': u"Here is an appropriate program:\n\n!bc pycod\nfrom fe_approx1D_numint import approximate, mesh_uniform, u_glob\nfrom sympy import sqrt, exp, sin, Symbol, lambdify, simplify\nimport numpy as np\nfrom math import log\n\nx = Symbol('x')\nA = 1\nw = 1\n\ncases = {'sqrt': {'f': sqrt(x), 'Omega': [0,1]},\n         'exp': {'f': A*exp(-w*x), 'Omega': [0, 3.0/w]},\n         'sin': {'f': A*sin(w*x), 'Omega': [0, 2*np.pi/w]}}\n\nresults = {}\nd_values = [1, 2, 3, 4]\n\nfor case in cases:\n    f = cases[case]['f']\n    f_func = lambdify([x], f, modules='numpy')\n    Omega = cases[case]['Omega']\n    results[case] = {}\n    for d in d_values:\n        results[case][d] = {'E': [], 'h': [], 'r': []}\n        for N_e in [4, 8, 16, 32, 64, 128]:\n            try:\n                c = approximate(\n                    f, symbolic=False,\n                    numint='GaussLegendre%d' % (d+1),\n                    d=d, N_e=N_e, Omega=Omega,\n                    filename='tmp_%s_d%d_e%d' % (case, d, N_e))\n            except np.linalg.linalg.LinAlgError as e:\n                print(str(e))\n                continue\n            vertices, cells, dof_map = mesh_uniform(\n                N_e, d, Omega, symbolic=False)\n            xc, u, _ = u_glob(c, vertices, cells, dof_map, 51)\n            e = f_func(xc) - u\n            # Trapezoidal integration of the L2 error over the\n            # xc/u patches\n            e2 = e**2\n            L2_error = 0\n            for i in range(len(xc)-1):\n                L2_error += 0.5*(e2[i+1] + e2[i])*(xc[i+1] - xc[i])\n            L2_error = np.sqrt(L2_error)\n            h = (Omega[1] - Omega[0])/float(N_e)\n            results[case][d]['E'].append(L2_error)\n            results[case][d]['h'].append(h)\n        # Compute rates\n        h = results[case][d]['h']\n        E = results[case][d]['E']\n        for i in range(len(h)-1):\n            r = log(E[i+1]/E[i])/log(h[i+1]/h[i])\n            results[case][d]['r'].append(round(r, 2))\n\nprint(results)\nfor case in results:\n    for d in sorted(results[case]):\n        print('case=%s d=%d, r: %s' % \\ \n              (case, d, results[case][d]['r']))\n\n!ec\nThe output becomes\n\n!bc\ncase=sqrt d=1, r: [1.0, 1.0, 1.0, 1.0, 1.0]\ncase=sqrt d=2, r: [1.0, 1.0, 1.0, 1.0, 1.0]\ncase=sqrt d=3, r: [1.0, 1.0, 1.0, 1.0, 1.0]\ncase=sqrt d=4, r: [1.0, 1.0, 1.0, 1.0, 1.0]\ncase=exp d=1, r: [2.01, 2.01, 2.0, 2.0, 2.0]\ncase=exp d=2, r: [2.81, 2.89, 2.94, 2.97, 2.98]\ncase=exp d=3, r: [3.98, 4.0, 4.0, 4.0, 4.0]\ncase=exp d=4, r: [4.87, 4.93, 4.96, 4.98, 4.99]\ncase=sin d=1, r: [2.15, 2.06, 2.02, 2.0, 2.0]\ncase=sin d=2, r: [2.68, 2.83, 2.93, 2.97, 2.99]\ncase=sin d=3, r: [4.06, 4.04, 4.01, 4.0, 4.0]\ncase=sin d=4, r: [4.79, 4.9, 4.96, 4.98, 4.99]\n\n!ec \nshowing that the convergence rate stabilizes quite quickly at $N_e=128$\ncells. While the theory predicts the rate as $d+1$, this is only\nfulfilled for the exponential and sine functions, while the square root\nfunctions gives a rate 1 regardless of $d$. The reason is that the\nestimate (ref{fem:approx:fe:error:theorem}) contains the integral of\nthe derivatives of $f$ over $[0,1]$. For $f=\\sqrt{x}$, we\nhave $f'=\\frac{1}{2} x^{-1/2}$, $f''=-\\frac{1}{4}x^{-3/2}$, and all integrals\nof $f''$ and higher derivatives are infinite on $[0,L]$. Our experiments\nshow that the method still converges, but $f$ is not smooth enough that\nhigher-order elements give superior convergence rates.",
  'solution_file': None,
  'subex': [],
  'text': u'The theory (ref{fem:approx:fe:error:theorem}) from Section\nref{fem:approx:fe:error} predicts that the error in the P$d$\napproximation of a function should behave as $h^{d+1}$, where $h$ is\nthe length of the element. Use experiments to verify this asymptotic\nbehavior (i.e., for small enough $h$).  Choose three examples:\n$f(x)=Ae^{-\\omega x}$ on $[0,3/\\omega]$, $f(x) = A\\sin (\\omega x)$ on\n$\\Omega=[0, 2\\pi/\\omega]$ for constant $A$ and $\\omega$, and\n$f(x)=\\sqrt{x}$ on $[0,1]$.',
  'title': u'Investigate the approximation error in finite elements',
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 8,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_Heaviside_P1P2'],
  'heading': u'=====',
  'hints': [u'This $f$ can also be expressed in terms of the Heaviside function $H(x)$:\n$f(x) = H(x-{1/2})$.\nTherefore, $f$ can be defined by\n\n98 <<<!!CODE_BLOCK  pycod\nmaking the `approximate` function in the\n`fe_approx1D.py` module an obvious candidate to solve the\nproblem. However, `sympy` does not handle symbolic integration\nwith this particular integrand, and the `approximate` function faces a problem\nwhen converting `f` to a Python function (for plotting) since\n`Heaviside` is not an available function in `numpy`.\n\nAn alternative is to perform hand calculations. This is an instructive\ntask, but in practice only feasible for few elements and P1 and P2 elements.\nIt is better to copy the functions `element_matrix`, `element_vector`,\n`assemble`, and `approximate` from the `fe_approx1D_numint.py` file\nand edit these functions such that they can compute approximations\nwith `f` given as a Python function and not a symbolic expression.\nAlso assume that `phi` computed by the `basis` function is a Python\ncallable function. Remove all instances of the `symbolic` variable\nand associated code.'],
  'keywords': None,
  'label': u'fem:approx:fe:exer:Heaviside',
  'no': 18,
  'solution': u'The modifications of `element_matrix`, `element_vector`,\n`assemble`, and `approximate` from the `fe_approx1D_numint.py` file\nare listed below.\n\n!bc pycod\nfrom fe_approx1D_numint import mesh_uniform, u_glob\nfrom fe_approx1D import basis\nimport numpy as np\n\ndef element_matrix(phi, Omega_e, numint):\n    n = len(phi)\n    A_e = np.zeros((n, n))\n    h = Omega_e[1] - Omega_e[0]\n    detJ = h/2  # dx/dX\n    for r in range(n):\n        for s in range(r, n):\n            for j in range(len(numint[0])):\n                Xj, wj = numint[0][j], numint[1][j]\n                A_e[r,s] += phi[r](Xj)*phi[s](Xj)*detJ*wj\n            A_e[s,r] = A_e[r,s]\n    return A_e\n\ndef element_vector(f, phi, Omega_e, numint):\n    n = len(phi)\n    b_e = np.zeros(n)\n    h = Omega_e[1] - Omega_e[0]\n    detJ = h/2\n    for r in range(n):\n        for j in range(len(numint[0])):\n            Xj, wj = numint[0][j], numint[1][j]\n            xj = (Omega_e[0] + Omega_e[1])/2 + h/2*Xj  # mapping\n            b_e[r] += f(xj)*phi[r](Xj)*detJ*wj\n    return b_e\n\n\ndef assemble(vertices, cells, dof_map, phi, f, numint):\n    N_n = len(list(set(np.array(dof_map).ravel())))\n    N_e = len(cells)\n    A = np.zeros((N_n, N_n))\n    b = np.zeros(N_n)\n    for e in range(N_e):\n        Omega_e = [vertices[cells[e][0]], vertices[cells[e][1]]]\n        A_e = element_matrix(phi[e], Omega_e, numint)\n        b_e = element_vector(f, phi[e], Omega_e, numint)\n        #print(\'element\', e)\n        #print(b_e)\n        for r in range(len(dof_map[e])):\n            for s in range(len(dof_map[e])):\n                A[dof_map[e][r],dof_map[e][s]] += A_e[r,s]\n            b[dof_map[e][r]] += b_e[r]\n    return A, b\n\ndef approximate(f, d, N_e, numint, Omega=[0,1], filename=\'tmp\'):\n    """\n    Compute the finite element approximation, using Lagrange\n    elements of degree d, to a Python functionn f on a domain\n    Omega. N_e is the number of elements.\n    numint is the name of the numerical integration rule\n    (Trapezoidal, Simpson, GaussLegendre2, GaussLegendre3,\n    GaussLegendre4, etc.). numint=None implies exact\n    integration.\n    """\n    from math import sqrt\n    numint_name = numint  # save name\n    if numint == \'Trapezoidal\':\n        numint = [[-1, 1], [1, 1]]\n    elif numint == \'Simpson\':\n        numint = [[-1, 0, 1], [1./3, 4./3, 1./3]]\n    elif numint == \'Midpoint\':\n        numint = [[0], [2]]\n    elif numint == \'GaussLegendre2\':\n        numint = [[-1/sqrt(3), 1/sqrt(3)], [1, 1]]\n    elif numint == \'GaussLegendre3\':\n        numint = [[-sqrt(3./5), 0, sqrt(3./5)],\n                  [5./9, 8./9, 5./9]]\n    elif numint == \'GaussLegendre4\':\n        numint = [[-0.86113631, -0.33998104,  0.33998104,\n                   0.86113631],\n                  [ 0.34785485,  0.65214515,  0.65214515,\n                    0.34785485]]\n    elif numint == \'GaussLegendre5\':\n        numint = [[-0.90617985, -0.53846931, -0.        ,\n                   0.53846931,  0.90617985],\n                  [ 0.23692689,  0.47862867,  0.56888889,\n                    0.47862867,  0.23692689]]\n    elif numint is not None:\n        print(\'Numerical rule %s is not supported \'\\ \n              \'for numerical computing\' % numint)\n        sys.exit(1)\n\n\n    vertices, cells, dof_map = mesh_uniform(N_e, d, Omega)\n\n    # phi is a list where phi[e] holds the basis in cell no e\n    # (this is required by assemble, which can work with\n    # meshes with different types of elements).\n    # len(dof_map[e]) is the number of nodes in cell e,\n    # and the degree of the polynomial is len(dof_map[e])-1\n    phi = [basis(len(dof_map[e])-1) for e in range(N_e)]\n\n    A, b = assemble(vertices, cells, dof_map, phi, f,\n                    numint=numint)\n\n    print(\'cells:\', cells)\n    print(\'vertices:\', vertices)\n    print(\'dof_map:\', dof_map)\n    print(\'A:\\n\', A)\n    print(\'b:\\n\', b)\n    c = np.linalg.solve(A, b)\n    print(\'c:\\n\', c)\n\n    if filename is not None:\n        title = \'P%d, N_e=%d\' % (d, N_e)\n        title += \', integration: %s\' % numint_name\n        x_u, u, _ = u_glob(np.asarray(c), vertices, cells, dof_map,\n                           resolution_per_element=51)\n        x_f = np.linspace(Omega[0], Omega[1], 10001) # mesh for f\n        import scitools.std as plt\n        plt.plot(x_u, u, \'-\',\n                 x_f, f(x_f), \'--\')\n        plt.legend([\'u\', \'f\'])\n        plt.title(title)\n        plt.savefig(filename + \'.pdf\')\n        plt.savefig(filename + \'.png\')\n    return c\n\n!ec\nWith a purely numerical version of the `approximate` function, we can\neasily investigate the suggested approximations in this exercise:\n\n!bc pycod\ndef exercise():\n    def f(x):\n        if isinstance(x, (float,int)):\n            return 0 if x < 0.5 else 1\n        elif isinstance(x, np.ndarray):\n            return np.where(x < 0.5, 0, 1)\n\n    N_e_values = [2, 4, 8, 16]\n    for d in 1, 2, 3, 4:\n        for N_e in N_e_values:\n            approximate(f, numint=\'GaussLegendre%d\' % (d+1),\n                        d=d, N_e=N_e,\n                        filename=\'fe_Heaviside_P%d_%de\' % (d, N_e))\n        for ext in \'pdf\', \'png\':\n            cmd = \'doconce combine_images \'\n            cmd += ext + \' -2 \'\n            cmd += \' \'.join([\'fe_Heaviside_P%d_%de\' % (d, N_e)\n                             for N_e in N_e_values])\n            cmd += \' fe_Heaviside_P%d\' % d\n            print(cmd)\n            os.system(cmd)\n\n!ec\nRunning this function reveals that even finite elements\n(and not only sines, as demonstrated in Exercise ref{fem:approx:exer:Fourier})\ngive oscillations around a discontinuity.\n\nFIGURE: [fig/fe_Heaviside_P1, width=800 frac=1]\n\nFIGURE: [fig/fe_Heaviside_P2, width=800 frac=1]\n\nFIGURE: [fig/fe_Heaviside_P3, width=800 frac=1]\n\nFIGURE: [fig/fe_Heaviside_P4, width=800 frac=1]\n\n__Remarks.__\nIt is of extreme importance to use a Gauss-Legendre numerical integration\nrule that matches the degree of polynomials in the basis.\nUsing a rule with fewer points may lead to very strange results.',
  'solution_file': None,
  'subex': [],
  'text': u'Approximate the step function\n\n!bt\n\\begin{equation*} f(x) = \\left\\lbrace\\begin{array}{ll}\n0 & \\mbox{ if } 0\\leq x < {1/2},\\\\\n1 & \\mbox{ if } {1/2} \\leq x \\geq {1/2}\n\\end{array}\\right.\n\\end{equation*}\n\n!et\nby 2, 4, 8, and 16 elements and  P1, P2, P3, and P4. Compare approximations visually.',
  'title': u'Approximate a step function by finite elements',
  'type': u'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 9,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'approx2D_ls_orth'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:2Dsines:symbolic',
  'no': 19,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [],
             'solution': u'We 1) remove the `j` loop in the `least_squares` function and set\n`j = i`,\n2) make `A` a vector (i.e., $(N+1, 1)$ matrix as `b` and `c`),\n3) solve for `c[i,0]` as soon as `A[i,0]` and `b[i,0]` are computed.\n\n!bc pycod\nimport sympy as sym\nimport mpmath\n\ndef least_squares_orth(f, psi, Omega, symbolic=True,\n                       print_latex=False):\n    """\n    Given a function f(x,y) on a rectangular domain\n    Omega=[[xmin,xmax],[ymin,ymax]],\n    return the best approximation to f(x,y) in the space V\n    spanned by the functions in the list psi.\n    This function assumes that psi are orthogonal on Omega.\n    """\n    # Modification of least_squares function: drop the j loop,\n    # set j=i, compute c on the fly in the i loop.\n\n    N = len(psi) - 1\n    # Note that A, b, c becmes (N+1)x(N+1), use 1st column\n    A = sym.zeros(N+1)\n    b = sym.zeros(N+1)\n    c = sym.zeros(N+1)\n    x, y = sym.symbols(\'x y\')\n    print(\'...evaluating matrix...\', A.shape, b.shape, c.shape)\n    for i in range(N+1):\n        j = i\n        print(\'(%d,%d)\' % (i, j))\n\n        integrand = psi[i]*psi[j]\n        if symbolic:\n            I = sym.integrate(integrand,\n                             (x, Omega[0][0], Omega[0][1]),\n                             (y, Omega[1][0], Omega[1][1]))\n        if not symbolic or isinstance(I, sym.Integral):\n            # Could not integrate symbolically, use numerical int.\n            print(\'numerical integration of\', integrand)\n            integrand = sym.lambdify([x,y], integrand, \'mpmath\')\n            I = mpmath.quad(integrand,\n                            [Omega[0][0], Omega[0][1]],\n                            [Omega[1][0], Omega[1][1]])\n        A[i,0] = I\n\n        integrand = psi[i]*f\n        if symbolic:\n            I = sym.integrate(integrand,\n                             (x, Omega[0][0], Omega[0][1]),\n                             (y, Omega[1][0], Omega[1][1]))\n        if not symbolic or isinstance(I, sym.Integral):\n            # Could not integrate symbolically, use numerical int.\n            print(\'numerical integration of\', integrand)\n            integrand = sym.lambdify([x,y], integrand, \'mpmath\')\n            I = mpmath.quad(integrand,\n                            [Omega[0][0], Omega[0][1]],\n                            [Omega[1][0], Omega[1][1]])\n        b[i,0] = I\n        c[i,0] = b[i,0]/A[i,0]\n    print()\n    print(\'A:\\n\', A, \'\\nb:\\n\', b)\n    c = [c[i,0] for i in range(c.shape[0])]  # make list\n    print(\'coeff:\', c)\n\n    # c is a sympy Matrix object, numbers are in c[i,0]\n    u = sum(c[i]*psi[i] for i in range(len(psi)))\n    print(\'approximation:\', u)\n    print(\'f:\', sym.expand(f))\n    if print_latex:\n        print(sym.latex(A, mode=\'plain\'))\n        print(sym.latex(b, mode=\'plain\'))\n        print(sym.latex(c, mode=\'plain\'))\n    return u, c\n\n!ec',
             'text': u'Assume we have basis functions ${\\varphi}_i(x,y)$ in 2D that are\northogonal such that $({\\varphi}_i,{\\varphi}_j)=0$ when $i\\neq j$.  The\nfunction `least_squares` in the file "`approx2D.py`":\n"${fem_src}/fe_approx2D.py" will then spend much time on computing\noff-diagonal terms in the coefficient matrix that we know are zero.\nTo speed up the computations, make a version `least_squares_orth` that\nutilizes the orthogonality among the basis functions.'},
            {'answer': '',
             'file': None,
             'hints': [u'Get ideas from the function `least_squares_orth` in\nSection ref{fem:approx:global:orth} and\nfile "`approx1D.py`": "${fem_src}/fe_approx1D.py".'],
             'solution': u'A function for computing the basis functions may look like this:\n\n!bc pycod\ndef sine_basis(Nx, Ny):\n    """\n    Compute basis sin((p+1)*pi*x)*sin((q+1)*pi*y),\n    p=0,...,Nx, q=0,...,Ny.\n    """\n    x, y = sym.symbols(\'x y\')\n    psi = []\n    for q in range(0, Ny+1):\n        for p in range(0, Nx+1):\n            r = sym.sin((p+1)*sym.pi*x)*sym.sin((q+1)*sym.pi*y)\n            psi.append(r)\n    return psi\n\n!ec\n\nApplication of this basis to approximate the given function is coded in\nthe following function:\n\n!bc pycod\ndef demo(N):\n    """\n    Find the approximation of f by the least squares method.\n    The basis is sin((p+1)*pi*x)sin((q+1)*pi*y) where\n    0<p<=N, p<q<=N.\n    """\n    x, y = sym.symbols(\'x y\')\n    f = x*(1-x)*y*(1-y)*sym.exp(-x-y)\n\n    psi = sine_basis(N, N)\n\n    Omega = [[0,1], [0,1]]\n    u, c  = least_squares_orth(f, psi, Omega, symbolic=False)\n    from approx2D import comparison_plot\n    comparison_plot(f, u, Omega, title=\'N=%d\' % N)\n    print(c)\n\nif __name__==\'__main__\':\n    #test_least_squares_orth()\n    demo(N=2)\n\n!ec\nA lesson learned is that `symbolic=False` is important, otherwise `sympy`\nconsumes a lot of CPU time on trying to integrate symbolically.\n\nThe figure below shows the error in the approximation for $N=0$ (left)\nand $N=2$ (right). The coefficients for $N=2$ decay rapidly:\n\n!bc\n[0.025, 0.0047, 0.0014, 0.0047, 0.0009, 0.0003, 0.0014, 0.0003,\n 8.2e-5]\n\n!ec \n\nFIGURE: [fig/approx2D_ls_orth_sine_c, width=800 frac=1]',
             'text': u'Apply the function to approximate\n\n!bt\n\\[ f(x,y) = x(1-x)y(1-y)e^{-x-y}\\]\n\n!et\non $\\Omega = [0,1]\\times [0,1]$ via basis functions\n\n!bt\n\\[ {\\varphi}_i(x,y) = \\sin ((p+1)\\pi x)\\sin((q+1)\\pi y),\\quad i=q(N_x+1) + p,\n\\]\n\n!et\nwhere $p=0,\\ldots,N_x$ and $q=0,\\ldots,N_y$.'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': u"Let us use the basis in b), fix the coefficients of some function\n$f$, and check that the computed approximation, with the\nsame basis, has the same coefficients (this test employs the principle\nthat if $f\\in V$, then $u=f$).\n\n!bc pycod\ndef test_least_squares_orth():\n    # Use sine functions\n    x, y = sym.symbols('x y')\n    N = 2  # (N+1)**2 = 9 basis functions\n    psi = sine_basis(N, N)\n    f_coeff = [0]*len(psi)\n    f_coeff[3] = 2\n    f_coeff[4] = 3\n    f = sum(f_coeff[i]*psi[i] for i in range(len(psi)))\n    # Check that u exactly reproduces f\n    u, c = least_squares_orth(f, psi, Omega=[[0,1], [0,1]],\n                              symbolic=False)\n    import numpy as np\n    diff = np.abs(np.array(c) - np.array(f_coeff)).max()\n    print('diff:', diff)\n    tol = 1E-15\n    assert diff < tol\n\n!ec",
             'text': u'Make a unit test for the `least_squares_orth` function.'}],
  'text': u'',
  'title': u'2D approximation with orthogonal functions',
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 10,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_P1_trapez'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:1D:trapez',
  'no': 20,
  'solution': u'The Trapezoidal rule for integrals on $[-1,1]$\nis given by (ref{fem:approx:fe:numint1:trapez}).\nThe expressions for the entries in the element matrix\nare given by (ref{fem:approx:fe:mapping:Ae}) in\nSection ref{fem:approx:fe:mapping}:\n\n!bt\n\\begin{align*} \\tilde A^{(e)}_{r,s} &=\n\\int_{-1}^1 {\\tilde{\\varphi}}_r(X){\\tilde{\\varphi}}_s(X)\\det J\\,{\\, \\mathrm{d}X}\\\\\n&\\approx \\frac{h}{2}({\\tilde{\\varphi}}_r(-1){\\tilde{\\varphi}}_s(-1)\n+ {\\tilde{\\varphi}}_r(1){\\tilde{\\varphi}}_s(1)){\\thinspace .}\n\\end{align*}\n\n!et\nWe know that if ${\\tilde{\\varphi}}_r(\\pm 1)$ is 0 or 1, so evaluating\nthe formula above for $r,s=0,1$ gives\n\n!bt\n\\[ \\tilde A^{(e)} = \\frac{h}{2}\\left(\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\right){\\thinspace .}\\]\n\n!et\nAs usual, $h$ is the length of the element in physical coordinates.\n\nThe element vector in the reference element is given by\n(ref{fem:approx:fe:mapping:be}):\n\n!bt\n\\begin{align*}\n\\tilde b^{(e)}_{r} &=  \\int_{-1}^1 f(x(X)){\\tilde{\\varphi}}_r(X)\\det J\\,{\\, \\mathrm{d}X}\\\\\n&\\approx \\frac{h}{2}(f(x(-1)){\\tilde{\\varphi}}_r(-1)\n+ f(x(1)){\\tilde{\\varphi}}_r(1)){\\thinspace .}\n\\end{align*}\n\n!et\nEvaluating the formula for $r=0,1$ leads to\n\n!bt\n\\[ \\tilde b^{(e)} = \\frac{h}{2}\\left(\\begin{array}{c}\nf(x_L)\\\\\nf(x_R)\n\\end{array}\\right),\\]\n\n!et\nwhere $x_L$ and $x_R$ are the $x$ coordinates of the local points\n$X=-1$ and $X=1$, respectively.\n\nWith a uniform mesh with nodes $x_{i}=ih$, the element matrix and\nvectors assemble to a coefficient matrix\n\n!bt\n\\[ \\frac{h}{2}\\hbox{diag}(1, 2, \\ldots, 2, 1),\\]\n\n!et\nand right-hand side vector\n\n!bt\n\\[ \\frac{h}{2}(f(x_{0}), 2f(x_{1}), \\ldots, 2f(x_{N_n-1}),\nf(x_{N_n})){\\thinspace .}\\]\n\n!et\nThe factors $h/2$ and $2$ cancel, so we are left with the solution of\nthe system as\n\n!bt\n\\[ c_i = f(x_{i}){\\thinspace .}\\]\n\n!et',
  'solution_file': None,
  'subex': [],
  'text': u'Consider the approximation of some $f(x)$ on an interval $\\Omega$ using\nthe least squares or Galerkin methods with P1 elements. Derive\nthe element matrix and vector using the\nTrapezoidal rule (ref{fem:approx:fe:numint1:trapez}) for calculating\nintegrals on the reference element. Assemble the contributions, assuming\na uniform cell partitioning, and show that the resulting linear system\nhas the form $c_i=f(x_{i})$ for $i\\in{\\mathcal{I}_s}$.',
  'title': u'Use the Trapezoidal rule and P1 elements',
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 11,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_P1_vs_interp'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:1D:P1:vs:interp',
  'no': 21,
  'solution': '',
  'solution_file': None,
  'subex': [{'aftertext': u'\n',
             'answer': '',
             'file': None,
             'hints': [],
             'solution': '',
             'text': u'Plot $f(x)$ for $n=1,2,3$ and find the wavelength of the function.'},
            {'aftertext': u'\n',
             'answer': '',
             'file': None,
             'hints': [],
             'solution': '',
             'text': u'We want to use $N_P$ elements per wavelength. Show that the number\nof elements is then $nN_P$.'},
            {'answer': '',
             'file': None,
             'hints': [u'Use the `fe_approx1D_numint` module to compute $u$ and use\nthe technique from Section ref{fem:approx:fe:error} to\ncompute the norm of the error.',
                       u'Read up on the Nyquist\u2013Shannon sampling theorem.'],
             'solution': '',
             'text': u'The critical quantity for accuracy is the number of elements per\nwavelength, not the element size in itself. It therefore suffices\nto study an $f$ with just one wavelength in $\\Omega = [0,1]$.\nSet $\\epsilon = 0.5$.\n\nRun the least squares or projection/Galerkin method for\n$N_P=2,4,8,16,32$. Compute the error $E=||u-f||_{L^2}$.'},
            {'answer': '',
             'file': None,
             'hints': [],
             'solution': '',
             'text': u'Repeat the set of experiments in the above point, but\nuse interpolation/collocation based on the node points to\ncompute $u(x)$ (recall that $c_i$ is now simply $f(x_{i})$).\nCompute the error $E=||u-f||_{L^2}$.\nWhich method seems to be most accurate?'}],
  'text': u'We shall approximate the function\n\n!bt\n\\[ f(x) = 1 + \\epsilon\\sin (2\\pi nx),\\quad x\\in \\Omega = [0,1],\\]\n\n!et\nwhere $n\\in\\mathbb{Z}$ and $\\epsilon \\geq 0$.',
  'title': u'Compare P1 elements and interpolation',
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 12,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'approx3D'],
  'heading': u'=====',
  'hints': [u'Drop symbolic integration since it is in general too slow for 3D problems.\nAlso use `scipy.integrate.nquad` instead of `mpmath.quad`\nfor numerical integration, since it is much faster.'],
  'keywords': None,
  'label': u'fem:approx:fe:exer:3D:approx3D',
  'no': 22,
  'solution': u'We take a copy of `approx2D.py` and drop the `comparison_plot` function since\nplotting in 3D is much more complicated (could make a special version with\ncurves through lines in the 3D domain, for instance).\nFurthermore, we remove the lines with symbolic integration and replace\nthe calls to `mpmath.quad` by calls to\n`scipy.integrate.nquad`. The resulting function becomes\n\n!bc pycod\nimport sympy as sym\nimport numpy as np\nimport scipy.integrate\n\ndef least_squares(f, psi, Omega):\n    """\n    Given a function f(x,y,z) on a rectangular domain\n    Omega=[[xmin,xmax],[ymin,ymax],[zmin,zmax]],\n    return the best approximation to f in the space V\n    spanned by the functions in the list psi.\n    f and psi are symbolic (sympy) expressions, but will\n    be converted to numeric functions for faster integration.\n    """\n    N = len(psi) - 1\n    A = np.zeros((N+1, N+1))\n    b = np.zeros(N+1)\n    x, y, z = sym.symbols(\'x y z\')\n    f = sym.lambdify([x, y, z], f, modules=\'numpy\')\n    psi_sym = psi[:]  # take a copy, needed for forming u later\n    psi = [sym.lambdify([x, y, z], psi[i]) for i in range(len(psi))]\n\n    print(\'...evaluating matrix...\')\n    for i in range(N+1):\n        for j in range(i, N+1):\n            print(\'(%d,%d)\' % (i, j))\n\n            integrand = lambda x, y, z: psi[i](x,y,z)*psi[j](x,y,z)\n            I, err = scipy.integrate.nquad(\n                integrand,\n                [[Omega[0][0], Omega[0][1]],\n                 [Omega[1][0], Omega[1][1]],\n                 [Omega[2][0], Omega[2][1]]])\n            A[i,j] = A[j,i] = I\n        integrand = lambda x, y, z: psi[i](x,y,z)*f(x,y,z)\n        I, err = scipy.integrate.nquad(\n            integrand,\n            [[Omega[0][0], Omega[0][1]],\n             [Omega[1][0], Omega[1][1]],\n             [Omega[2][0], Omega[2][1]]])\n        b[i] = I\n    print()\n    c = np.linalg.solve(A, b)\n    if N <= 10:\n        print(\'A:\\n\', A, \'\\nb:\\n\', b)\n        print(\'coeff:\', c)\n    u = sum(c[i]*psi_sym[i] for i in range(len(psi_sym)))\n    print(\'approximation:\', u)\n    return u, c\n\n!ec\n\nAs test example, we can use the basis\n\n!bt\n\\[ {\\psi}_{p,q,r} = \\sin((p+1)\\pi x)\\sin((q+1)\\pi y)\\sin((r+1)\\pi z),\\]\n\n!et\nfor $p=1,\\ldots,N_x$, $q=1,\\ldots,N_y$, $r=1,\\ldots,N_z$.\nWe choose $f$ as some prescribed combination of these functions and\ncheck that the computed $u$ is exactly equal to $f$.\n\n!bc pycod\ndef sine_basis(Nx, Ny, Nz):\n    """\n    Compute basis sin((p+1)*pi*x)*sin((q+1)*pi*y)*sin((r+1)*pi*z),\n    p=0,...,Nx, q=0,...,Ny, r=0,...,Nz.\n    """\n    x, y, z = sym.symbols(\'x y z\')\n    psi = []\n    for r in range(0, Nz+1):\n        for q in range(0, Ny+1):\n            for p in range(0, Nx+1):\n                s = sym.sin((p+1)*sym.pi*x)*\\ \n                    sym.sin((q+1)*sym.pi*y)*sym.sin((r+1)*sym.pi*z)\n                psi.append(s)\n    return psi\n\ndef test_least_squares():\n    # Use sine functions\n    x, y, z = sym.symbols(\'x y z\')\n    N = 1  # (N+1)**3 = 8 basis functions\n    psi = sine_basis(N, N, N)\n    f_coeff = [0]*len(psi)\n    f_coeff[3] = 2\n    f_coeff[4] = 3\n    f = sum(f_coeff[i]*psi[i] for i in range(len(psi)))\n    # Check that u exactly reproduces f\n    u, c = least_squares(f, psi, Omega=[[0,1], [0,1], [0,1]])\n    diff = np.abs(np.array(c) - np.array(f_coeff)).max()\n    print(\'diff:\', diff)\n    tol = 1E-15\n    assert diff < tol\n\n!ec',
  'solution_file': None,
  'subex': [],
  'text': u'Extend the "`approx2D.py`": "${fem_src}/approx2D.py" code to 3D\nby applying ideas from Section ref{fem:approx:3D:global}.\nConstruct some 3D problem to make a test function for the\nimplementation.',
  'title': u'Implement 3D computations with global basis functions',
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 13,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': [u'fe_P2_simpson'],
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': u'fem:approx:fe:exer:1D:simpson',
  'no': 23,
  'solution': u"Simpson's rule for integrals on $[-1,1]$\nis given by (ref{fem:approx:fe:numint1:Simpson}).\nThe expressions for the entries in the element matrix\nare given by (ref{fem:approx:fe:mapping:Ae}):\n\n!bt\n\\begin{align*} \\tilde A^{(e)}_{r,s} &=\n\\int_{-1}^1 {\\tilde{\\varphi}}_r(X){\\tilde{\\varphi}}_s(X)\\det J\\,{\\, \\mathrm{d}X}\\\\\n&\\approx \\frac{1}{3}\\frac{h}{2}({\\tilde{\\varphi}}_r(-1){\\tilde{\\varphi}}_s(-1)\n+ 4{\\tilde{\\varphi}}_r(0){\\tilde{\\varphi}}_s(0)\n+ {\\tilde{\\varphi}}_r(1){\\tilde{\\varphi}}_s(1)){\\thinspace .}\n\\end{align*}\n\n!et\nThe expressions for ${\\tilde{\\varphi}}_r(X)$ are given by\n(ref{fem:approx:fe:mapping:P1:phi0})-(ref{fem:approx:fe:mapping:P1:phi1}).\nEvaluating the formula for $r,s=0,1,2$ gives the element matrix\n\n!bt\n\\[ \\tilde A^{(e)} = \\frac{h}{6}\\left(\\begin{array}{ccc}\n1 & 0 & 0\\\\\n0 & 4 & 0\\\\\n0 & 0 & 1\n\\end{array}\\right){\\thinspace .}\\]\n\n!et\nAs usual, $h$ is the length of the element in physical coordinates.\n\nThe element vector in the reference element is given by\n(ref{fem:approx:fe:mapping:be}):\n\n!bt\n\\begin{align*}\n\\tilde b^{(e)}_{r} &=  \\int_{-1}^1 f(x(X)){\\tilde{\\varphi}}_r(X)\\det J\\,{\\, \\mathrm{d}X}\\\\\n&\\approx \\frac{1}{3}\\frac{h}{2}(f(x(-1)){\\tilde{\\varphi}}_r(-1)\n+ 4f(x(0)){\\tilde{\\varphi}}_r(0)\n+ f(x(1)){\\tilde{\\varphi}}_r(1)){\\thinspace .}\n\\end{align*}\n\n!et\nEvaluating the formula for $r=0,1,2$ leads to\n\n!bt\n\\[ \\tilde b^{(e)} = \\frac{h}{2}\\left(\\begin{array}{c}\nf(x_L)\\\\\n4f(x_c)\nf(x_R)\n\\end{array}\\right),\\]\n\n!et\nwhere $x_L$, $x_c$, and $x_R$ are the $x$ coordinates of the local points\n$X=-1$, $X=0$, and $X=1$, respectively. These correspond to the nodes\nin the element.\n\nWith a uniform mesh with nodes $x_{i}=ih$, the element matrix and\nvectors assemble to a coefficient matrix\n\n!bt\n\\[ \\frac{h}{6}\\hbox{diag}(1, 4, 2, 4, 2, 4, \\ldots, 2, 4, 1),\\]\n\n!et\nand right-hand side vector\n\n!bt\n\\[ \\frac{h}{6}(f(x_{0}), 4f(x_{1}), 2f(x_{2}),\n4f(x_{3}), 2f(x_{4}), \\ldots, 2f(x_{N_n-2}),\n4f(x_{N_n-1}), f(x_{N_n})){\\thinspace .}\\]\n\n!et\nThe factors $h/6$, $2$ and $4$ all cancel, so we are left with the solution of\nthe system as\n\n!bt\n\\[ c_i = f(x_{i}){\\thinspace .}\\]\n\n!et",
  'solution_file': None,
  'subex': [],
  'text': u"Redo Exercise ref{fem:approx:fe:exer:1D:trapez}, but use P2\nelements and Simpson's rule based on sampling the integrands at\nthe nodes in the reference cell.",
  'title': u"Use Simpson's rule and P2 elements",
  'type': u'Exercise',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': 14,
  'chapter_no': 2,
  'chapter_title': u'Function approximation by finite elements',
  'chapter_type': 'Chapter',
  'closing_remarks': '',
  'file': None,
  'heading': u'=====',
  'hints': [],
  'keywords': None,
  'label': None,
  'no': 24,
  'solution': '',
  'solution_file': None,
  'subex': [],
  'text': u'Extend the code from Section ref{fem:approx:fenics:2D:2} to 3D.',
  'title': u'Make a 3D code for Lagrange elements of arbitrary order',
  'type': u'Exercise',
  'type_visible': True}]